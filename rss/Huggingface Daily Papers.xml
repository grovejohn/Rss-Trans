<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface 日报 - 由 RSSHub(https://github.com/DIYgod/RSSHub) 精心制作</description>
    <lastBuildDate>Thu, 02 May 2024 12:49:33 GMT</lastBuildDate>
    <item>
      <title>STT：利用 Transformers 实现自动驾驶状态跟踪</title>
      <link>https://arxiv.org/abs/2405.00236</link>
      <description><![CDATA[跟踪三维空间中的物体对于自动驾驶至关重要。为了确保驾驶安全，跟踪器必须能够跨帧可靠地跟踪物体，并准确估计它们当前的速度和加速度等状态。现有的工作经常关注关联任务，而忽略状态估计的模型性能或部署复杂的启发式方法来预测状态。在本文中，我们提出了 STT，一种使用 Transformer 构建的状态跟踪模型，它可以持续跟踪场景中的对象，同时准确预测其状态。 STT 通过长期的检测历史消耗丰富的外观、几何和运动信号，并针对数据关联和状态估计任务进行联合优化。由于像 MOTA 和 MOTP 这样的标准跟踪指标无法捕获两个任务在更广泛的对象状态下的综合性能，因此我们使用称为 S-MOTA 和 MOTPS 的新指标来扩展它们，以解决这一限制。 STT 在 Waymo 开放数据集上实现了具有竞争力的实时性能。]]></description>
      <guid>https://arxiv.org/abs/2405.00236</guid>
      <pubDate>Thu, 02 May 2024 05:56:19 GMT</pubDate>
    </item>
    <item>
      <title>具有跨模式匹配的自动创意选择</title>
      <link>https://arxiv.org/abs/2405.00029</link>
      <description><![CDATA[应用程序开发人员通过使用应用程序图像创建产品页面并对搜索词进行竞价来宣传他们的应用程序。因此，应用程序图像与搜索词高度相关至关重要。该问题的解决方案需要图像文本匹配模型来预测所选图像和搜索词之间的匹配质量。在这项工作中，我们提出了一种基于微调预训练 LXMERT 模型的新颖方法，将应用程序图像与搜索词进行匹配。我们表明，与 CLIP 模型以及使用 Transformer 模型搜索词和 ResNet 模型搜索图像的基线相比，我们显着提高了匹配精度。我们使用两组标签来评估我们的方法：给定应用程序的广告商关联（图像，搜索词）对，以及对（图像，搜索词）对之间相关性的人工评分。我们的方法在广告商相关的真实数据方面实现了 0.96 AUC 分数，比 Transformer+ResNet 基线和微调 CLIP 模型高出 8% 和 14%。对于人类标记的真实情况，我们的方法达到了 0.95 AUC 分数，比 Transformer+ResNet 基线和微调 CLIP 模型高出 16% 和 17%。]]></description>
      <guid>https://arxiv.org/abs/2405.00029</guid>
      <pubDate>Thu, 02 May 2024 05:53:15 GMT</pubDate>
    </item>
    <item>
      <title>Paint by Inpaint：学习通过先删除图像对象来添加图像对象</title>
      <link>https://arxiv.org/abs/2404.18212</link>
      <description><![CDATA[随着文本条件扩散模型的引入，图像编辑取得了长足进步。尽管取得了这些进展，但根据文本指令无缝地将对象添加到图像中而无需用户提供的输入掩码仍然是一项挑战。我们利用删除对象（Inpaint）比添加对象的逆过程（Paint）简单得多的洞察力来解决这个问题，这归因于使用分割掩码数据集以及在这些掩码内进行修复的修复模型。利用这一认识，通过实施自动化和广泛的管道，我们整理了一个经过过滤的大规模图像数据集，其中包含图像对及其相应的对象删除版本。使用这些对，我们训练扩散模型来逆向修复过程，有效地将对象添加到图像中。与其他编辑数据集不同，我们的数据集以自然目标图像而不是合成图像为特色；此外，它通过构造保持源和目标之间的一致性。此外，我们利用大型视觉语言模型来提供已删除对象的详细描述，并使用大型语言模型将这些描述转换为多样化的自然语言指令。我们证明了训练后的模型在质量和数量上都超越了现有的模型，并向社区发布了与训练后的模型一起的大规模数据集。]]></description>
      <guid>https://arxiv.org/abs/2404.18212</guid>
      <pubDate>Thu, 02 May 2024 05:48:18 GMT</pubDate>
    </item>
    <item>
      <title>语言模型对齐的自玩偏好优化</title>
      <link>https://arxiv.org/abs/2405.00675</link>
      <description><![CDATA[传统的人类反馈强化学习 (RLHF) 方法依赖于 Bradley-Terry 模型等参数模型，无法捕捉人类偏好中的不及物性和非理性。最近的进展表明，直接使用偏好概率可以更准确地反映人类偏好，从而实现更灵活和准确的语言模型对齐。在本文中，我们提出了一种基于自我博弈的语言模型对齐方法，该方法将问题视为恒定和两人博弈，旨在确定纳什均衡策略。我们的方法被称为自我博弈偏好优化（SPPO），通过迭代策略更新来逼近纳什均衡，并享有理论收敛保证。我们的方法可以有效地增加所选响应的对数似然并降低被拒绝响应的对数似然，这是通过直接偏好优化（DPO）和身份偏好优化（IPO）等对称成对损失无法轻松实现的。在我们的实验中，仅使用来自 UltraFeedback 数据集的 60k 提示（无响应）并且没有任何提示增强，通过利用仅具有 0.4B 参数的预训练偏好模型 PairRM，SPPO 可以通过微调 Mistral-7B 获得模型Instruct-v0.2 在 AlpacaEval 2.0 上对 GPT-4-Turbo 实现了 28.53% 的最先进的长度控制胜率。它还在 MT-Bench 和 Open LLM 排行榜上优于（迭代）DPO 和 IPO。值得注意的是，SPPO 的强大性能是在没有来自 GPT-4 或其他更强的语言模型的额外外部监督（例如响应、偏好等）的情况下实现的。]]></description>
      <guid>https://arxiv.org/abs/2405.00675</guid>
      <pubDate>Thu, 02 May 2024 05:45:17 GMT</pubDate>
    </item>
    <item>
      <title>Clover：具有顺序知识的回归轻量级推测解码</title>
      <link>https://arxiv.org/abs/2405.00263</link>
      <description><![CDATA[由于自回归解码的要求与大多数当代 GPU 的设计不匹配，大型语言模型 (LLM) 效率低下。具体来说，数十亿到数万亿的参数必须通过其有限的内存带宽加载到GPU缓存中进行计算，但实际上只计算了一小批令牌。因此，GPU 的大部分时间都花在内存传输上，而不是计算上。最近，并行解码（一种推测解码算法）变得越来越流行，并且在生成过程中表现出了令人印象深刻的效率提高。它向大型模型引入了额外的解码头，使它们能够同时预测多个后续标记，并在单个解码步骤中验证这些候选延续。然而，这种方法偏离了预训练期间使用的下一个令牌预测的训练目标，导致候选令牌的命中率较低。在本文中，我们提出了一种新的推测性解码算法 Clover，它将顺序知识集成到并行解码过程中。这一增强提高了投机者的命中率，从而提高了整体效率。 Clover 通过回归连接传输预先推测的令牌的顺序知识，然后使用注意力解码器来整合这些推测的令牌。此外，Clover 还包含一个增强块，可以修改隐藏状态，以更好地符合推测生成的目的，而不是下一个代币预测。实验结果表明，Clover 在 Baichuan-Small 上的性能比基线高出 91%，在 Baichuan-Large 上的性能比基线高出 146%，在 Baichuan-Large 上的性能比之前表现最好的方法 Medusa 的性能高出 37%。小号和百川大号分别占 57%。]]></description>
      <guid>https://arxiv.org/abs/2405.00263</guid>
      <pubDate>Thu, 02 May 2024 04:50:08 GMT</pubDate>
    </item>
    <item>
      <title>SemantiCodec：适用于一般声音的超低比特率语义音频编解码器</title>
      <link>https://arxiv.org/abs/2405.00233</link>
      <description><![CDATA[大型语言模型 (LLM) 通过将音频转换为离散标记的音频编解码器具有显着先进的音频处理能力，从而能够将语言建模技术应用于音频数据。然而，传统编解码器通常以高比特率或在语音等狭窄领域内运行，并且缺乏有效语言建模所需的语义线索。为了解决这些挑战，我们推出了 SemantiCodec，这是一种新颖的编解码器，旨在将不同音频类型（包括语音、一般音频和音乐）的音频压缩成每秒不到一百个令牌，而不会影响质量。 SemantiCodec 采用双编码器架构：使用自监督 AudioMAE 的语义编码器，在大量音频数据上使用 k 均值聚类进行离散化，以及用于捕获剩余细节的声学编码器。语义和声学编码器输出用于通过基于扩散模型的解码器重建音频。 SemantiCodec 提供三种变体，令牌速率分别为每秒 25、50 和 100，支持 0.31 kbps 到 1.43 kbps 之间的一系列超低比特率。实验结果表明 SemantiCodec 在重建质量方面明显优于最先进的 Descript 编解码器。我们的结果还表明，SemantiCodec 比所有评估的音频编解码器包含更丰富的语义信息，即使比特率明显较低。我们的代码和演示可在 https://haoheliu.github.io/SemantiCodec/ 获取。]]></description>
      <guid>https://arxiv.org/abs/2405.00233</guid>
      <pubDate>Thu, 02 May 2024 04:44:14 GMT</pubDate>
    </item>
    <item>
      <title>编辑批量大小越大越好吗？ -- Llama-3模型编辑的实证研究</title>
      <link>https://arxiv.org/abs/2405.00664</link>
      <description><![CDATA[本研究提出了针对最新大型语言模型 Llama-3 的有针对性的模型编辑分析。我们探索流行的模型编辑技术 - ROME、MEMIT 和 EMMET 的功效，这些技术专为精确的图层干预而设计。我们通过评估确定了最有效的目标编辑层，该评估涵盖三种不同策略的多达 4096 次编辑：顺序编辑、批量编辑和我们称为顺序批量编辑的混合方法。我们的研究结果表明，与在相同数量的编辑中顺序使用较小的编辑批次相比，增加编辑批次大小可能会更显着地降低模型性能。因此，我们认为顺序模型编辑是扩展模型编辑方法的重要组成部分，未来的研究应该集中在结合批量和顺序编辑的方法上。这一观察表明当前模型编辑方法存在潜在的局限性，这些方法推动了更大的编辑批量大小，我们希望它为未来优化批量大小和模型编辑性能的研究铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2405.00664</guid>
      <pubDate>Thu, 02 May 2024 03:09:06 GMT</pubDate>
    </item>
    <item>
      <title>仔细检查大型语言模型在小学算术中的表现</title>
      <link>https://arxiv.org/abs/2405.00332</link>
      <description><![CDATA[大型语言模型 (LLM) 在许多数学推理基准上取得了令人瞩目的成功。然而，人们越来越担心，这种性能的一部分实际上反映了数据集污染，即与基准问题非常相似的数据泄漏到训练数据中，而不是真正的推理能力。为了严格调查这一说法，我们委托 Grade School Math 1000 (GSM1k)。 GSM1k 的设计反映了已建立的 GSM8k 基准的风格和复杂性，GSM8k 基准是衡量基本数学推理的黄金标准。我们确保这两个基准在人类解决率、解决步骤数、答案大小等重要指标上具有可比性。在评估 GSM1k 上领先的开源和闭源法学硕士时，我们观察到准确性下降高达 13%，几个模型系列（例如 Phi 和 Mistral）显示出几乎所有模型大小的系统过度拟合的证据。与此同时，许多模型，尤其是前沿模型（例如 Gemini/GPT/Claude）显示出最小的过度拟合迹象。进一步的分析表明，模型从 GSM8k 生成示例的概率与其 GSM8k 和 GSM1k 之间的性能差距之间存在正相关关系（Spearman 的 r^2=0.32），这表明许多模型可能部分记住了 GSM8k。]]></description>
      <guid>https://arxiv.org/abs/2405.00332</guid>
      <pubDate>Thu, 02 May 2024 02:56:03 GMT</pubDate>
    </item>
    <item>
      <title>具有神经补偿的光谱修剪高斯场</title>
      <link>https://arxiv.org/abs/2405.00676</link>
      <description><![CDATA[近年来，3D高斯溅射作为一种新颖的3D表示方法，因其渲染速度快、渲染质量高而受到人们的关注。然而，这会带来高内存消耗，例如，训练有素的高斯场可能会利用 300 万个高斯基元和超过 700 MB 的内存。我们将这种高内存占用归因于缺乏对基元之间关系的考虑。在本文中，我们提出了一种具有谱修剪和神经补偿功能的内存高效高斯场，名为 SUNDAE。一方面，我们在高斯基元集上构建一个图来建模它们的关系，并设计一个频谱下采样模块来修剪基元，同时保留所需的信号。另一方面，为了补偿剪枝高斯的质量损失，我们利用轻量级神经网络头来混合分散特征，这可以有效地补偿质量损失，同时捕获其权重中基元之间的关系。我们通过广泛的成果展示了圣代的性能。例如，在 Mip-NeRF360 数据集上，SUNDAE 使用 104 MB 内存可在 145 FPS 下实现 26.80 PSNR，而普通高斯泼溅算法可使用 523 MB 内存在 160 FPS 下实现 25.60 PSNR。代码可在 https://runyiyang.github.io/projects/SUNDAE/ 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.00676</guid>
      <pubDate>Thu, 02 May 2024 02:14:33 GMT</pubDate>
    </item>
    </channel>
</rss>