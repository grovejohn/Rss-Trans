<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - RSSHub 用爱制作的(https://github.com/DIYgod/RSSHub)</description>
    <lastBuildDate>Tue, 23 Apr 2024 02:39:01 GMT</lastBuildDate>
    <item>
      <title>SEED-X：具有统一多粒度理解和生成的多模态模型</title>
      <link>https://arxiv.org/abs/2404.14396</link>
      <description><![CDATA[多模态基础模型的快速发展已经证明了视觉语言理解和生成方面的重大进展，例如我们之前的工作 SEED-LLaMA。然而，其能力与现实世界的适用性之间仍然存在差距，这主要是由于该模型有效响应各种用户指令并与各种视觉数据交互的能力有限。在这项工作中，我们致力于通过集成两个增强功能来弥补这一差距：（1）理解任意大小和比例的图像，以及（2）实现多粒度图像生成。我们提出了一个统一且通用的基础模型，即 SEED-X，它能够为理解和生成任务建模多粒度视觉语义。除了公共基准测试中具有竞争力的结果之外，SEED-X 还展示了其在指令调整后跨各个领域处理实际应用程序的有效性。我们希望我们的工作能够激发未来研究多功能多模态基础模型在实际应用中可以实现的目标。模型、代码和数据集将在 https://github.com/AILab-CVC/SEED-X 中发布。]]></description>
      <guid>https://arxiv.org/abs/2404.14396</guid>
      <pubDate>Tue, 23 Apr 2024 02:15:24 GMT</pubDate>
    </item>
    <item>
      <title>MultiBooth：从文本生成图像中的所有概念</title>
      <link>https://arxiv.org/abs/2404.14239</link>
      <description><![CDATA[本文介绍了 MultiBooth，这是一种新颖且高效的技术，用于从文本生成图像中进行多概念定制。尽管定制生成方法取得了显着进步，特别是扩散模型的成功，但由于概念保真度低和推理成本高，现有方法常常难以应对多概念场景。 MultiBooth 通过将多概念生成过程分为两个阶段来解决这些问题：单概念学习阶段和多概念集成阶段。在单概念学习阶段，我们采用多模态图像编码器和有效的概念编码技术来学习每个概念的简洁且有区别的表示。在多概念整合阶段，我们使用边界框来定义交叉注意力图中每个概念的生成区域。该方法使得能够在其指定区域内创建单独的概念，从而促进多概念图像的形成。该策略不仅提高了概念保真度，还降低了额外的推理成本。 MultiBooth 在定性和定量评估方面都超越了各种基线，展示了其卓越的性能和计算效率。项目页面：https://multibooth.github.io/]]></description>
      <guid>https://arxiv.org/abs/2404.14239</guid>
      <pubDate>Tue, 23 Apr 2024 01:52:56 GMT</pubDate>
    </item>
    <item>
      <title>音乐一致性模型</title>
      <link>https://arxiv.org/abs/2404.13358</link>
      <description><![CDATA[一致性模型在促进高效图像/视频生成、以最少的采样步骤进行合成方面表现出了卓越的能力。事实证明，它有利于减轻与扩散模型相关的计算负担。然而，一致性模型在音乐生成中的应用在很大程度上仍未得到探索。为了解决这一差距，我们提出了音乐一致性模型（MusicCM），它利用一致性模型的概念来有效地合成音乐剪辑的梅尔频谱图，在保持高质量的同时最大限度地减少采样步骤的数量。 MusicCM 模型以现有的文本到音乐扩散模型为基础，结合了一致性蒸馏和对抗性鉴别器训练。此外，我们发现通过将多个扩散过程与共享约束相结合来生成扩展的连贯音乐是有益的。实验结果揭示了我们的模型在计算效率、保真度和自然度方面的有效性。值得注意的是，MusicCM 只需四个采样步骤即可实现无缝音乐合成，例如音乐剪辑每分钟仅需一秒，展示了实时应用的潜力。]]></description>
      <guid>https://arxiv.org/abs/2404.13358</guid>
      <pubDate>Tue, 23 Apr 2024 01:48:40 GMT</pubDate>
    </item>
    </channel>
</rss>