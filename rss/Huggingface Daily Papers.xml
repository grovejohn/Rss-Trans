<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - 由 RSSHub 用爱制作（https://github.com/DIYgod/RSSHub）</description>
    <lastBuildDate>Thu, 18 Apr 2024 11:10:24 GMT</lastBuildDate>
    <item>
      <title>具有潜在扩散的长格式音乐生成</title>
      <link>https://arxiv.org/abs/2404.10301</link>
      <description><![CDATA[基于音频的音乐生成模型最近取得了长足的进步，但迄今为止尚未成功地生成具有连贯音乐结构的完整长度的音乐曲目。我们证明，通过在长时间上下文上训练生成模型，可以生成长达 4 分 45 秒的长音乐。我们的模型由一个在高度下采样的连续潜在表示（潜在速率为 21.5Hz）上运行的扩散变压器组成。根据音频质量和提示对齐的指标，它获得了最先进的世代，主观测试表明它可以产生具有连贯结构的完整长度的音乐。]]></description>
      <guid>https://arxiv.org/abs/2404.10301</guid>
      <pubDate>Wed, 17 Apr 2024 17:05:12 GMT</pubDate>
    </item>
    <item>
      <title>在许多模拟世界中扩展可指导的代理</title>
      <link>https://arxiv.org/abs/2404.10179</link>
      <description><![CDATA[构建能够在任何 3D 环境中遵循任意语言指令的具身 AI 系统是创建通用 AI 的关键挑战。要实现这一目标，需要学习将语言扎根于感知和具身动作中，以便完成复杂的任务。可扩展、可指导、多世界代理 (SIMA) 项目通过训练代理在各种虚拟 3D 环境中遵循自由形式的指令来解决此问题，包括精心策划的研究环境以及开放式商业视频游戏。我们的目标是开发一个可指导的代理，它可以在任何模拟 3D 环境中完成人类可以做的任何事情。我们的方法侧重于语言驱动的通用性，同时施加最少的假设。我们的代理使用通用的、类似人类的界面实时与环境交互：输入是图像观察和语言指令，输出是键盘和鼠标操作。这种通用方法具有挑战性，但它允许代理在许多视觉复杂且语义丰富的环境中扎根语言，同时还允许我们在新的环境中轻松运行代理。在本文中，我们描述了我们的动机和目标、取得的初步进展以及在几个不同的研究环境和各种商业视频游戏上取得的有希望的初步结果。]]></description>
      <guid>https://arxiv.org/abs/2404.10179</guid>
      <pubDate>Wed, 17 Apr 2024 13:41:38 GMT</pubDate>
    </item>
    </channel>
</rss>