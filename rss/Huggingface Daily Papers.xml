<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - 由 RSSHub 用爱制作（https://github.com/DIYgod/RSSHub）</description>
    <lastBuildDate>Wed, 17 Apr 2024 21:12:46 GMT</lastBuildDate>
    <item>
      <title>具有潜在扩散的长格式音乐生成</title>
      <link>https://arxiv.org/abs/2404.10301</link>
      <description><![CDATA[基于音频的音乐生成模型最近取得了长足的进步，但迄今为止尚未成功地生成具有连贯音乐结构的完整长度的音乐曲目。我们证明，通过在长时间上下文上训练生成模型，可以生成长达 4 分 45 秒的长音乐。我们的模型由一个在高度下采样的连续潜在表示（潜在速率为 21.5Hz）上运行的扩散变压器组成。根据音频质量和提示对齐的指标，它获得了最先进的世代，主观测试表明它可以产生具有连贯结构的完整长度的音乐。]]></description>
      <guid>https://arxiv.org/abs/2404.10301</guid>
      <pubDate>Wed, 17 Apr 2024 17:05:12 GMT</pubDate>
    </item>
    <item>
      <title>在许多模拟世界中扩展可指导的代理</title>
      <link>https://arxiv.org/abs/2404.10179</link>
      <description><![CDATA[构建可以在任何 3D 环境中遵循任意语言指令的具体 AI 系统是创建通用 AI 的关键挑战。实现这一目标需要学习将语言融入感知和具体行动中，以完成复杂的任务。可扩展、可指导、多世界代理 (SIMA) 项目通过训练代理在各种虚拟 3D 环境中遵循自由形式的指令来解决这个问题，包括策划的研究环境以及开放式商业视频游戏。我们的目标是开发一种可指导的代理，可以完成人类在任何模拟 3D 环境中可以做的任何事情。我们的方法侧重于语言驱动的通用性，同时施加最小的假设。我们的代理使用通用的类人界面与环境实时交互：输入是图像观察和语言指令，输出是键盘和鼠标操作。这种通用方法具有挑战性，但它允许代理在许多视觉上复杂且语义丰富的环境中使用语言，同时也允许我们在新环境中轻松运行代理。在本文中，我们描述了我们的动机和目标、我们取得的初步进展，以及在几种不同的研究环境和各种商业视频游戏中有望取得的初步结果。]]></description>
      <guid>https://arxiv.org/abs/2404.10179</guid>
      <pubDate>Wed, 17 Apr 2024 13:41:38 GMT</pubDate>
    </item>
    </channel>
</rss>