<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - 由 RSSHub 用爱制作（https://github.com/DIYgod/RSSHub）</description>
    <lastBuildDate>Mon, 06 May 2024 18:36:29 GMT</lastBuildDate>
    <item>
      <title>使用单个图像对自定义文本到图像模型</title>
      <link>https://arxiv.org/abs/2405.01536</link>
      <description><![CDATA[艺术重新诠释是对参考作品进行变体的实践，制作出展现独特艺术风格的配对艺术品。我们询问是否可以使用这样的图像对来定制生成模型以捕获所展示的风格差异。我们提出了配对定制，这是一种新的定制方法，可以从单个图像对中学习风格差异，然后将获得的风格应用于生成过程。与学习从图像集合中模仿单个概念的现有方法不同，我们的方法捕获了配对图像之间的风格差异。这使我们能够应用风格改变，而不会过度拟合示例中的特定图像内容。为了解决这个新任务，我们采用了一种联合优化方法，将样式和内容显式地分离到不同的 LoRA 权重空间中。我们优化这些样式和内容权重以重现样式和内容图像，同时鼓励它们的正交性。在推理过程中，我们根据学习到的权重，通过新的风格指导来修改扩散过程。定性和定量实验都表明，我们的方法可以有效地学习风格，同时避免过度拟合图像内容，突出了从单个图像对建模此类风格差异的潜力。]]></description>
      <guid>https://arxiv.org/abs/2405.01536</guid>
      <pubDate>Fri, 03 May 2024 03:52:55 GMT</pubDate>
    </item>
    <item>
      <title>FLAME：大型语言模型的事实感知对齐</title>
      <link>https://arxiv.org/abs/2405.01525</link>
      <description><![CDATA[对齐是一个标准程序，用于微调预训练的大型语言模型 (LLM)，使其遵循自然语言指令并充当有用的 AI 助手。然而，我们观察到，传统的对齐过程无法提高法学硕士的事实准确性，并且常常导致产生更多虚假事实（即幻觉）。在本文中，我们研究如何使 LLM 对齐过程更加真实，首先确定两个对齐步骤中导致幻觉的因素：监督微调（SFT）和强化学习（RL）。特别是，我们发现对法学硕士进行新知识或不熟悉的文本培训可能会鼓励产生幻觉。这使得 SFT 不太真实，因为它训练的人类标记数据对于法学硕士来说可能是新颖的。此外，标准强化学习中使用的奖励函数也会鼓励产生幻觉，因为它引导法学硕士对各种指令提供更有帮助的响应，通常更喜欢更长、更详细的响应。基于这些观察，我们提出了事实感知对齐，包括通过直接偏好优化的事实感知 SFT 和事实感知 RL。实验表明，我们提出的事实意识对齐指导法学硕士输出更多的事实响应，同时保持指令跟踪能力。]]></description>
      <guid>https://arxiv.org/abs/2405.01525</guid>
      <pubDate>Fri, 03 May 2024 02:57:52 GMT</pubDate>
    </item>
    <item>
      <title>NeMo-Aligner：用于高效模型对齐的可扩展工具包</title>
      <link>https://arxiv.org/abs/2405.01481</link>
      <description><![CDATA[让大型语言模型 (LLM) 与人类价值观和偏好保持一致对于使其有用且安全至关重要。然而，构建高效的工具来执行对齐可能具有挑战性，特别是对于通常包含数百或数千亿参数的最大和最有能力的法学硕士而言。我们创建了 NeMo-Aligner，这是一个用于模型对齐的工具包，可以有效地扩展到使用数百个 GPU 进行训练。 NeMo-Aligner 为模型对齐的主要范例提供了高度优化和可扩展的实现，例如：来自人类反馈的强化学习 (RLHF)、直接偏好优化 (DPO)、SteerLM 和自玩微调 (SPIN)。此外，我们的工具包支持在参数高效微调 (PEFT) 设置中运行大多数对齐技术。 NeMo-Aligner 专为可扩展性而设计，可以轻松支持其他对齐技术。它是开源的，具有 Apache 2.0 许可证，我们邀请社区贡献 https://github.com/NVIDIA/NeMo-Aligner]]></description>
      <guid>https://arxiv.org/abs/2405.01481</guid>
      <pubDate>Fri, 03 May 2024 02:30:01 GMT</pubDate>
    </item>
    <item>
      <title>Prometheus 2：专门用于评估其他语言模型的开源语言模型</title>
      <link>https://arxiv.org/abs/2405.01535</link>
      <description><![CDATA[GPT-4 等专有 LM 通常用于评估各种 LM 响应的质量。然而，包括透明度、可控性和可负担性在内的担忧强烈推动了专门从事评估的开源语言模型的开发。另一方面，现有的开放评估器 LM 表现出严重的缺点：1）它们发出的分数与人类分配的分数明显不同，2）它们缺乏执行直接评估和成对排名（两种最流行的评估形式）的灵活性。此外，他们不具备根据自定义评估标准进行评估的能力，而是关注有用性和无害性等一般属性。为了解决这些问题，我们引入了 Prometheus 2，这是一个比其前身更强大的评估器 LM，它密切反映了人类和 GPT-4 的判断。此外，它能够处理直接评估和按用户定义的评估标准分组的成对排名格式。在四个直接评估基准和四个成对排名基准上，Prometheus 2 在所有测试的开放评估器 LM 中与人类和专有 LM 法官的相关性和一致性最高。我们的模型、代码和数据均可在 https://github.com/prometheus-eval/prometheus-eval 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.01535</guid>
      <pubDate>Fri, 03 May 2024 02:22:40 GMT</pubDate>
    </item>
    <item>
      <title>LLM-AD：基于大语言模型的音频描述系统</title>
      <link>https://arxiv.org/abs/2405.00983</link>
      <description><![CDATA[音频描述 (AD) 的开发是使视频内容更易于访问和包容的关键一步。传统上，AD 制作需要大量熟练劳动力，而现有的自动化方法仍然需要大量培训来集成多模态输入并将输出从字幕样式定制为 AD 样式。在本文中，我们介绍了一种自动化 AD 生成流程，该流程利用了 GPT-4V(ision) 强大的多模态和指令跟踪能力。值得注意的是，我们的方法采用了现成的组件，无需额外培训。它生成的 AD 不仅符合既定的自然语言 AD 制作标准，而且还通过基于跟踪的字符识别模块在各帧之间保持上下文一致的字符信息。对 MAD 数据集的彻底分析表明，我们的方法在自动化 AD 制作中实现了与基于学习的方法相当的性能，CIDEr 得分为 20.5 证实了这一点。]]></description>
      <guid>https://arxiv.org/abs/2405.00983</guid>
      <pubDate>Fri, 03 May 2024 02:20:08 GMT</pubDate>
    </item>
    <item>
      <title>WildChat：100 万个 ChatGPT 野外交互日志</title>
      <link>https://arxiv.org/abs/2405.01470</link>
      <description><![CDATA[GPT-4 和 ChatGPT 等聊天机器人现在正在为数百万用户提供服务。尽管它们被广泛使用，但仍然缺乏公共数据集来展示这些工具在实践中如何被用户群体使用。为了弥补这一差距，我们为在线用户提供了免费访问 ChatGPT 的机会，以换取他们肯定、同意的选择，以匿名方式收集他们的聊天记录和请求标头。据此，我们编译了 WildChat，这是一个包含 100 万个用户 ChatGPT 对话的语料库，其中包含超过 250 万个交互回合。我们将 WildChat 与其他流行的用户聊天机器人交互数据集进行比较，发现我们的数据集提供了最多样化的用户提示，包含最多数量的语言，并提供了最丰富的潜在有毒用例供研究人员研究。除了带时间戳的聊天记录之外，我们还使用人口统计数据丰富了数据集，包括州、国家/地区和散列 IP 地址以及请求标头。这种增强可以对不同地理区域和时间维度的用户行为进行更详细的分析。最后，由于它捕获了广泛的用例，我们展示了该数据集在微调指令跟踪模型方面的潜在效用。 WildChat 在 AI2 ImpACT 许可证下于 https://wildchat.allen.ai 发布。]]></description>
      <guid>https://arxiv.org/abs/2405.01470</guid>
      <pubDate>Fri, 03 May 2024 02:15:27 GMT</pubDate>
    </item>
    <item>
      <title>LoRA Land：310 个可与 GPT-4 竞争的微调法学硕士，技术报告</title>
      <link>https://arxiv.org/abs/2405.00732</link>
      <description><![CDATA[低秩适应 (LoRA) 已成为大型语言模型 (LLM) 参数高效微调 (PEFT) 最广泛采用的方法之一。 LoRA 减少了可训练参数的数量和内存使用量，同时实现了与完全微调相当的性能。我们的目标是评估在现实应用中使用 LoRA 进行微调的法学硕士培训和服务的可行性。首先，我们测量了在 10 个基本模型和 31 个任务（总共 310 个模型）中使用量化低等级适配器进行微调的 LLM 的质量。我们发现 4 位 LoRA 微调模型平均比基础模型高 34 个点，比 GPT-4 平均高 10 个点。其次，我们研究了最有效的微调基础模型，并评估了任务复杂性启发法在预测微调结果方面的相关性和预测能力。最后，我们评估了 LoRAX 的延迟和并发能力，LoRAX 是一款开源多 LoRA 推理服务器，可使用共享基础模型权重和动态适配器加载，促进在单个 GPU 上部署多个 LoRA 微调模型。 LoRAX 为 LoRA Land 提供支持，LoRA Land 是一个 Web 应用程序，在具有 80GB 内存的单个 NVIDIA A100 GPU 上托管 25 个经过 LoRA 微调的 Mistral-7B LLM。 LoRA Land 强调聘用多个专业法学硕士相对于单一通用法学硕士的质量和成本效益。]]></description>
      <guid>https://arxiv.org/abs/2405.00732</guid>
      <pubDate>Fri, 03 May 2024 02:11:46 GMT</pubDate>
    </item>
    <item>
      <title>StoryDiffusion：用于长距离图像和视频生成的一致自注意力</title>
      <link>https://arxiv.org/abs/2405.01434</link>
      <description><![CDATA[对于最近基于扩散的生成模型，在一系列生成的图像中保持一致的内容，特别是那些包含主题和复杂细节的图像，提出了重大挑战。在本文中，我们提出了一种新的自注意力计算方法，称为一致性自注意力，它显着提高了生成图像之间的一致性，并以零样本方式增强了流行的基于预训练扩散的文本到图像模型。为了将我们的方法扩展到远程视频生成，我们进一步引入了一种新颖的语义空间时间运动预测模块，称为语义运动预测器。它被训练来估计语义空间中两个提供的图像之间的运动条件。该模块将生成的图像序列转换为具有平滑过渡和一致主题的视频，比仅基于潜在空间的模块更加稳定，特别是在长视频生成的情况下。通过合并这两个新颖的组件，我们的框架（称为 StoryDiffusion）可以描述基于文本的故事，其中包含包含丰富内容的一致图像或视频。拟议的 StoryDiffusion 涵盖了通过图像和视频的呈现来生成视觉故事的开创性探索，我们希望这能够从建筑修改方面激发更多的研究。我们的代码已在 https://github.com/HVision-NKU/StoryDiffusion 上公开发布。]]></description>
      <guid>https://arxiv.org/abs/2405.01434</guid>
      <pubDate>Fri, 03 May 2024 01:53:55 GMT</pubDate>
    </item>
    </channel>
</rss>