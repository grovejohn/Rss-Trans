<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - 由 RSSHub 用爱制作（https://github.com/DIYgod/RSSHub）</description>
    <lastBuildDate>Thu, 04 Apr 2024 21:11:11 GMT</lastBuildDate>
    <item>
      <title>Freditor：通过频率分解进行高保真且可转移的 NeRF 编辑</title>
      <link>https://arxiv.org/abs/2404.02514</link>
      <description><![CDATA[本文通过频率分解实现了高保真、可转移的 NeRF 编辑。最近的 NeRF 编辑管道将 2D 风格化结果提升到 3D 场景，但结果模糊，并且由于 2D 编辑之间的不一致而无法捕获详细结构。我们的重要见解是，与高频部分相比，编辑后图像的低频部分更具多视图一致性。而且外观风格主要表现在低频部分，内容细节尤其集中在高频部分。这促使我们对低频成分进行编辑，从而产生高保真的编辑场景。此外，编辑是在低频特征空间中进行的，可以实现稳定的强度控制和新颖的场景传输。在真实感数据集上进行的综合实验证明了高保真和可转移 NeRF 编辑的卓越性能。项目页面位于 https://aigc3d.github.io/freditor。]]></description>
      <guid>https://arxiv.org/abs/2404.02514</guid>
      <pubDate>Thu, 04 Apr 2024 06:11:51 GMT</pubDate>
    </item>
    <item>
      <title>作为编译器的语言模型：模拟伪代码执行改进语言模型中的算法推理</title>
      <link>https://arxiv.org/abs/2404.02575</link>
      <description><![CDATA[算法推理是指理解问题背后的复杂模式并将其分解为解决问题的一系列推理步骤的能力。算法推理的这种性质使其对大型语言模型（LLM）构成挑战，尽管它们在其他推理任务中表现出了良好的性能。在此背景下，最近的一些研究受到严格而精确的语法的启发，使用编程语言（例如Python）来表达解决给定实例/问题（例如思维程序）所需的逻辑。然而，编写在单个推理调用中动态表达正确逻辑的可执行代码并非易事。此外，专门为某个实例生成的代码不能被其他实例重用，即使它们来自同一任务并且可能需要相同的逻辑来解决。本文提出了 Think-and-Execute，这是一种新颖的框架，它将语言模型的推理过程分解为两个步骤。 （1）在Think中，我们发现了一个在所有实例之间共享的任务级逻辑，用于解决给定的任务，然后用伪代码表达该逻辑； (2)在Execute中，我们进一步针对每个实例定制生成的伪代码并模拟代码的执行。通过对七个算法推理任务的广泛实验，我们证明了思考和执行的有效性。与执行特定实例推理的几个强基线（例如 CoT 和 PoT）相比，我们的方法更好地改进了 LM 的推理，这表明发现任务级逻辑的帮助。此外，我们还表明，与自然语言相比，伪代码可以更好地指导 LM 的推理，即使它们经过训练可以遵循自然语言指令。]]></description>
      <guid>https://arxiv.org/abs/2404.02575</guid>
      <pubDate>Thu, 04 Apr 2024 04:30:28 GMT</pubDate>
    </item>
    <item>
      <title>深度混合：在基于 Transformer 的语言模型中动态分配计算</title>
      <link>https://arxiv.org/abs/2404.02258</link>
      <description><![CDATA[基于 Transformer 的语言模型在输入序列中均匀分布 FLOP。在这项工作中，我们证明 Transformer 可以学习将 FLOP（或计算）动态分配到序列中的特定位置，从而优化模型深度上不同层的序列分配。我们的方法通过限制可以参与给定层的自注意力和 MLP 计算的令牌数量 (k) 来强制执行总计算预算。要处理的令牌由网络使用 top-k 路由机制确定。由于 k 是先验定义的，因此与其他条件计算技术不同，这个简单的过程使用具有已知张量大小的静态计算图。然而，由于 k 个标记的身份是可变的，因此该方法可能会在时间和模型深度维度上不均匀地消耗 FLOP。因此，计算支出总体上是完全可预测的，但在令牌级别是动态的和上下文敏感的。以这种方式训练的模型不仅可以学习动态分配计算，而且可以高效地进行计算。这些模型与训练的等效 FLOPS 和挂钟时间的基线性能相匹配，但每次前向传递只需要一小部分 FLOP，并且在训练后采样期间的步进速度可以快 50% 以上。]]></description>
      <guid>https://arxiv.org/abs/2404.02258</guid>
      <pubDate>Thu, 04 Apr 2024 04:18:46 GMT</pubDate>
    </item>
    <item>
      <title>ChatGLM-Math：通过自我批评管道提高大型语言模型中的数学问题解决能力</title>
      <link>https://arxiv.org/abs/2404.02893</link>
      <description><![CDATA[大型语言模型（LLM）已经表现出对人类语言的出色掌握，但在需要解决数学问题的现实应用中仍然举步维艰。虽然开发了许多增强法学硕士数学的策略和数据集，但在部署的法学硕士系统中同时维护和提高语言和数学能力仍然是一个挑战。在这项工作中，我们定制了自我批评管道，它解决了法学硕士数学中的挑战。 LLM对齐的反馈学习阶段。我们首先从法学硕士本身训练一个通用的数学批判模型来提供反馈信号。然后，我们依次对法学硕士自己的一代进行拒绝微调和直接偏好优化来收集数据。基于 ChatGLM3-32B，我们对学术数据集和新创建的挑战性数据集 MathUserEval 进行了一系列实验。结果表明，我们的管道显着增强了法学硕士解决数学问题的能力，同时仍然提高了其语言能力，其表现优于可能大两倍的法学硕士。相关技术已部署到在线服务法学硕士ChatGLM\url{https://chatglm.cn}。相关评估数据集和脚本发布于https://github.com/THUDM/ChatGLM-Math。]]></description>
      <guid>https://arxiv.org/abs/2404.02893</guid>
      <pubDate>Thu, 04 Apr 2024 03:16:22 GMT</pubDate>
    </item>
    <item>
      <title>交叉注意力使文本到图像扩散模型的推理变得麻烦</title>
      <link>https://arxiv.org/abs/2404.02747</link>
      <description><![CDATA[本研究探讨了文本条件扩散模型推理过程中交叉注意力的作用。我们发现，经过几个推理步骤后，交叉注意力输出会收敛到一个固定点。因此，收敛的时间点自然地将整个推理过程分为两个阶段：初始语义规划阶段，模型依靠交叉注意力来规划面向文本的视觉语义，以及随后的保真度提高阶段，在此期间，模型尝试根据先前计划的语义生成图像。令人惊讶的是，在保真度提高阶段忽略文本条件不仅降低了计算复杂度，而且还保持了模型性能。这产生了一种简单且无需训练的方法，称为 TGATE，用于高效生成，一旦交叉注意力输出收敛，该方法就会对其进行缓存，并在剩余的推理步骤中保持固定。我们对 MS-COCO 验证集的实证研究证实了其有效性。 TGATE的源代码可以在https://github.com/HaozheLiu-ST/T-GATE获取。]]></description>
      <guid>https://arxiv.org/abs/2404.02747</guid>
      <pubDate>Thu, 04 Apr 2024 03:12:11 GMT</pubDate>
    </item>
    <item>
      <title>视觉自回归建模：通过下一代预测生成可扩展的图像</title>
      <link>https://arxiv.org/abs/2404.02905</link>
      <description><![CDATA[我们提出了视觉自回归建模（VAR），这是一种新一代范式，它将图像的自回归学习重新定义为从粗到细的“下一个尺度预测”或“下一个分辨率预测”，与标准光栅扫描“下一个分辨率”不同。代币预测”。这种简单、直观的方法使自回归 (AR) 转换器能够快速学习视觉分布并很好地概括：VAR 首次使 AR 模型在图像生成方面超越了扩散转换器。在 ImageNet 256x256 基准上，VAR 通过将 Frechet 起始距离 (FID) 从 18.65 提高到 1.80、起始分数 (IS) 从 80.4 提高到 356.4，显着改善了 AR 基线，推理速度提高了约 20 倍。实证还验证了 VAR 在图像质量、推理速度、数据效率和可扩展性等多个维度上均优于 Diffusion Transformer (DiT)。扩大 VAR 模型表现出清晰的幂律缩放定律，与法学硕士中观察到的相似，线性相关系数接近 -0.998，这是确凿的证据。 VAR 进一步展示了下游任务中的零样本泛化能力，包括图像内画、外画和编辑。这些结果表明 VAR 最初模拟了法学硕士的两个重要属性：缩放定律和零样本任务泛化。我们已经发布了所有模型和代码，以推动AR/VAR模型在视觉生成和统一学习方面的探索。]]></description>
      <guid>https://arxiv.org/abs/2404.02905</guid>
      <pubDate>Thu, 04 Apr 2024 03:07:13 GMT</pubDate>
    </item>
    <item>
      <title>基于扩散的文本到图像生成的可扩展性</title>
      <link>https://arxiv.org/abs/2404.02883</link>
      <description><![CDATA[对于法学硕士的发展来说，扩大模型和数据规模非常成功。然而，基于扩散的文本到图像（T2I）模型的缩放法则尚未得到充分探索。目前还不清楚如何有效地扩展模型以降低成本以获得更好的性能。不同的训练设置和昂贵的训练成本使得公平的模型比较变得极其困难。在这项工作中，我们通过对去噪骨干网和训练集的缩放进行广泛而严格的消融，实证研究基于扩散的 T2I 模型的缩放特性，包括在高达 6 亿图像的数据集上训练从 0.4B 到 4B 参数的缩放 UNet 和 Transformer 变体。对于模型缩放，我们发现交叉注意力的位置和数量区分了现有 UNet 设计的性能。与增加通道数相比，增加变换器块对于改善文本图像对齐来说参数效率更高。然后，我们确定了一种高效的 UNet 变体，它比 SDXL 的 UNet 小 45%，快 28%。在数据扩展方面，我们表明训练集的质量和多样性比简单的数据集大小更重要。增加字幕密度和多样性可以提高文本图像对齐性能和学习效率。最后，我们提供缩放函数来预测文本图像对齐性能，作为模型大小、计算和数据集大小的缩放函数。]]></description>
      <guid>https://arxiv.org/abs/2404.02883</guid>
      <pubDate>Thu, 04 Apr 2024 03:00:07 GMT</pubDate>
    </item>
    <item>
      <title>InstantStyle：文本到图像生成中风格保留的免费午餐</title>
      <link>https://arxiv.org/abs/2404.02733</link>
      <description><![CDATA[基于免调整扩散的模型在图像个性化和定制领域表现出了巨大的潜力。然而，尽管取得了显着的进步，当前的模型在生成风格一致的图像方面仍然面临着一些复杂的挑战。首先，风格的概念本质上是不确定的，它包含色彩、材质、氛围、设计、结构等多种元素。其次，基于反演的方法很容易出现风格退化，通常会导致细粒度细节的丢失。最后，基于适配器的方法经常需要对每个参考图像进行细致的权重调整，以实现风格强度和文本可控性之间的平衡。在本文中，我们首先研究几个令人信服但经常被忽视的观察结果。然后，我们继续介绍 InstantStyle，这是一个旨在通过实施两个关键策略来解决这些问题的框架：1）一种简单的机制，可以将样式和内容与特征空间内的参考图像解耦，基于相同空间内的特征的假设可以相互相加或相减。 2）将参考图像特征专门注入到特定风格的块中，从而防止风格泄漏并避免繁琐的权重调整，这通常是参数较多的设计的特征。我们的工作展示了卓越的视觉风格化结果，在两者之间取得了最佳平衡风格的强度和文本元素的可控性。我们的代码将在 https://github.com/InstantStyle/InstantStyle 上提供。]]></description>
      <guid>https://arxiv.org/abs/2404.02733</guid>
      <pubDate>Thu, 04 Apr 2024 02:51:01 GMT</pubDate>
    </item>
    </channel>
</rss>