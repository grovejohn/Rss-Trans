<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - RSSHub 用爱制作的(https://github.com/DIYgod/RSSHub)</description>
    <lastBuildDate>Thu, 02 May 2024 05:36:26 GMT</lastBuildDate>
    <item>
      <title>编辑批量大小总是越大越好吗？ -- Llama-3模型编辑的实证研究</title>
      <link>https://arxiv.org/abs/2405.00664</link>
      <description><![CDATA[本研究提出了针对最新大型语言模型 Llama-3 的有针对性的模型编辑分析。我们探索了流行的模型编辑技术 - ROME、MEMIT 和 EMMET 的功效，这些技术专为精确的图层干预而设计。我们通过评估确定了最有效的目标编辑层，该评估涵盖三种不同策略的多达 4096 次编辑：顺序编辑、批量编辑和我们称为顺序批量编辑的混合方法。我们的研究结果表明，与在相同数量的编辑中顺序使用较小的编辑批次相比，增加编辑批次大小可能会更显着地降低模型性能。因此，我们认为顺序模型编辑是扩展模型编辑方法的重要组成部分，未来的研究应该集中在结合批量和顺序编辑的方法上。这一观察表明当前模型编辑方法存在潜在的局限性，这些方法推动了更大的编辑批量大小，我们希望它为未来优化批量大小和模型编辑性能的研究铺平道路。]]></description>
      <guid>https://arxiv.org/abs/2405.00664</guid>
      <pubDate>Thu, 02 May 2024 03:09:06 GMT</pubDate>
    </item>
    <item>
      <title>仔细检查大型语言模型在小学算术中的表现</title>
      <link>https://arxiv.org/abs/2405.00332</link>
      <description><![CDATA[大型语言模型 (LLM) 在许多数学推理基准上取得了令人瞩目的成功。然而，人们越来越担心，其中一些性能实际上反映了数据集污染，即与基准问题非常相似的数据泄漏到训练数据中，而不是真正的推理能力。为了严格调查这一说法，我们委托 Grade School Math 1000 (GSM1k)。 GSM1k 的设计反映了已建立的 GSM8k 基准的风格和复杂性，GSM8k 基准是衡量基本数学推理的黄金标准。我们确保这两个基准在人类解决率、解决步骤数、答案大小等重要指标上具有可比性。在评估 GSM1k 上领先的开源和闭源法学硕士时，我们观察到准确性下降高达 13%，几个模型系列（例如 Phi 和 Mistral）显示出几乎所有模型大小的系统过度拟合的证据。与此同时，许多模型，尤其是前沿模型（例如 Gemini/GPT/Claude）显示出最小的过度拟合迹象。进一步的分析表明，模型从 GSM8k 生成示例的概率与其在 GSM8k 和 GSM1k 之间的性能差距之间存在正相关关系（Spearman&#39;s r^2=0.32），这表明许多模型可能部分记住了 GSM8k。]]></description>
      <guid>https://arxiv.org/abs/2405.00332</guid>
      <pubDate>Thu, 02 May 2024 02:56:03 GMT</pubDate>
    </item>
    <item>
      <title>具有神经补偿的光谱修剪高斯场</title>
      <link>https://arxiv.org/abs/2405.00676</link>
      <description><![CDATA[近年来，3D高斯溅射作为一种新颖的3D表示方法，因其渲染速度快、渲染质量高而受到人们的关注。然而，这会带来高内存消耗，例如，训练有素的高斯场可能会利用 300 万个高斯基元和超过 700 MB 的内存。我们将这种高内存占用归因于缺乏对基元之间关系的考虑。在本文中，我们提出了一种具有谱修剪和神经补偿功能的内存高效高斯场，名为 SUNDAE。一方面，我们在高斯基元集上构建一个图来建模它们的关系，并设计一个频谱下采样模块来修剪基元，同时保留所需的信号。另一方面，为了补偿剪枝高斯的质量损失，我们利用轻量级神经网络头来混合分散特征，这可以有效地补偿质量损失，同时捕获其权重中基元之间的关系。我们通过广泛的成果展示了圣代的性能。例如，在 Mip-NeRF360 数据集上，SUNDAE 使用 104 MB 内存可在 145 FPS 下实现 26.80 PSNR，而普通高斯泼溅算法可使用 523 MB 内存在 160 FPS 下实现 25.60 PSNR。代码可在 https://runyiyang.github.io/projects/SUNDAE/ 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2405.00676</guid>
      <pubDate>Thu, 02 May 2024 02:14:33 GMT</pubDate>
    </item>
    </channel>
</rss>