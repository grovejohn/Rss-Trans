<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - RSSHub 用爱制作的(https://github.com/DIYgod/RSSHub)</description>
    <lastBuildDate>Mon, 29 Apr 2024 14:13:26 GMT</lastBuildDate>
    <item>
      <title>MaPa：文本驱动的 3D 形状真实感材质绘画</title>
      <link>https://arxiv.org/abs/2404.17569</link>
      <description><![CDATA[本文旨在从文本描述生成 3D 网格材料。与合成纹理图的现有方法不同，我们建议生成分段程序材质图作为外观表示，它支持高质量渲染并在编辑方面提供很大的灵活性。我们建议利用预先训练的 2D 扩散模型作为连接文本和材料图的桥梁，而不是依赖广泛的配对数据（即具有材料图和相应文本描述的 3D 网格）来训练材料图生成模型。具体来说，我们的方法将形状分解为一组分段，并设计分段控制的扩散模型来合成与网格部分对齐的 2D 图像。基于生成的图像，我们初始化材质图的参数，并通过可微分渲染模块对其进行微调，以生成符合文本描述的材质。大量的实验证明了我们的框架在真实感、分辨率和可编辑性方面比现有方法具有优越的性能。项目页面：https://zhanghe3z.github.io/MaPa/]]></description>
      <guid>https://arxiv.org/abs/2404.17569</guid>
      <pubDate>Mon, 29 Apr 2024 02:33:17 GMT</pubDate>
    </item>
    <item>
      <title>AdvPrompter：法学硕士的快速自适应对抗性提示</title>
      <link>https://arxiv.org/abs/2404.16873</link>
      <description><![CDATA[虽然最近大型语言模型 (LLM) 取得了显着的成功，但它们很容易受到某些越狱攻击，从而导致生成不适当或有害的内容。手动红队需要找到导致此类越狱的对抗性提示，例如通过向给定指令添加后缀，这种方式效率低下且耗时。另一方面，自动对抗性提示生成通常会导致语义上无意义的攻击，这些攻击很容易被基于困惑的过滤器检测到，可能需要来自 TargetLLM 的梯度信息，或者由于令牌上耗时的离散优化过程而无法很好地扩展空间。在本文中，我们提出了一种新颖的方法，该方法使用另一种 LLM（称为 AdvPrompter）在几秒钟内生成人类可读的对抗性提示，比现有的基于优化的方法快 800 倍。我们使用一种新颖的算法来训练 AdvPrompter，该算法不需要访问 TargetLLM 的梯度。该过程在两个步骤之间交替：（1）通过优化 AdvPrompter 预测生成高质量的目标对抗性后缀，以及（2）使用生成的对抗性后缀对 AdvPrompter 进行低秩微调。经过训练的 AdvPrompter 会生成后缀，这些后缀会掩盖输入指令而不改变其含义，从而引诱 TargetLLM 给出有害的响应。流行的开源 TargetLLM 上的实验结果显示了 AdvBench 数据集上最先进的结果，这些结果也转移到闭源黑盒 LLM API。此外，我们证明，通过对 AdvPrompter 生成的合成数据集进行微调，LLM 可以更加稳健地抵御越狱攻击，同时保持性能，即高 MMLU 分数。]]></description>
      <guid>https://arxiv.org/abs/2404.16873</guid>
      <pubDate>Mon, 29 Apr 2024 01:43:06 GMT</pubDate>
    </item>
    <item>
      <title>HaLo-NeRF：学习几何引导语义来探索不受约束的照片集</title>
      <link>https://arxiv.org/abs/2404.16845</link>
      <description><![CDATA[包含大量摄影师拍摄的照片的互联网图像集有望实现对大型旅游地标的数字探索。然而，先前的工作主要集中在几何重建和可视化上，忽略了语言在为导航和细粒度理解提供语义界面方面的关键作用。在受限的 3D 领域中，最近的方法利用视觉和语言模型作为 2D 视觉语义的强大先验。虽然这些模型表现出对广泛视觉语义的出色理解，但由于缺乏建筑领域的专业知识，它们难以处理描绘此类旅游地标的不受约束的照片集。在这项工作中，我们提出了一个定位系统，通过利用 SOTA 视觉和语言模型的力量以及理解地标场景语义的适应性，将描绘大规模地标的场景的神经表示与描述场景内语义区域的文本连接起来。为了用细粒度的知识支持此类模型，我们利用包含相似地标图像以及弱相关文本信息的大规模互联网数据。我们的方法建立在这样的前提之上：物理上基于空间的图像可以为本地化新概念提供强大的监督信号，其语义可以通过大型语言模型从互联网文本元数据中解锁。我们使用场景视图之间的对应关系来引导对这些语义的空间理解，为最终提升为体积场景表示的 3D 兼容分割提供指导。我们的结果表明，HaLo-NeRF 可以准确定位与建筑地标相关的各种语义概念，超越了其他 3D 模型以及强大的 2D 分割基线的结果。我们的项目页面位于 https://tau-vailab.github.io/HaLo-NeRF/。]]></description>
      <guid>https://arxiv.org/abs/2404.16845</guid>
      <pubDate>Mon, 29 Apr 2024 01:20:01 GMT</pubDate>
    </item>
    <item>
      <title>PLLaVA：从图像到视频的无参数 LLaVA 扩展，用于视频密集字幕</title>
      <link>https://arxiv.org/abs/2404.16994</link>
      <description><![CDATA[视觉语言预训练已显著提升了各种图像语言应用的性能。然而，视频相关任务的预训练过程需要异常大的计算和数据资源，这阻碍了视频语言模型的进步。本文研究了一种简单、高效且资源少的方法来调整现有的图像语言预训练模型以进行密集视频理解。我们的初步实验表明，直接在视频数据集上使用多帧作为输入对预训练的图像语言模型进行微调会导致性能饱和甚至下降。我们进一步的研究表明，这在很大程度上归因于学习到的高范数视觉特征的偏差。受这一发现的启发，我们提出了一种简单但有效的池化策略来平滑时间维度上的特征分布，从而减少极端特征的主导影响。新模型称为 Pooling LLaVA，简称为 Pooling LLaVA，在现代基准数据集上实现了视频问答和字幕任务的全新最佳性能。值得注意的是，在最近流行的 Video ChatGPT 基准测试中，PLLaVA 在五个评估维度上的平均得分为 3.48（满分 5 分），比 GPT4V（IG-VLM）之前的 SOTA 结果高出 9%。在最新的多选基准 MVBench 上，PLLaVA 在 20 个子任务中的平均准确率为 58.1%，比 GPT4V（IG-VLM）高出 14.5%。代码可在 https://github.com/magic-research/PLLaVA 上找到。]]></description>
      <guid>https://arxiv.org/abs/2404.16994</guid>
      <pubDate>Mon, 29 Apr 2024 01:12:08 GMT</pubDate>
    </item>
    </channel>
</rss>