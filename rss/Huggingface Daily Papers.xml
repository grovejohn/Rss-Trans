<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>拥抱日报</title>
    <link>https://huggingface.co/papers</link>
    <description>Huggingface Daily Papers - RSSHub 用爱制作的(https://github.com/DIYgod/RSSHub)</description>
    <lastBuildDate>Fri, 12 Apr 2024 10:13:21 GMT</lastBuildDate>
    <item>
      <title>WILBUR：用于稳健且准确的网络代理的自适应上下文学习</title>
      <link>https://arxiv.org/abs/2404.05902</link>
      <description><![CDATA[在网络代理研究领域，同时实现泛化和准确性仍然是一个具有挑战性的问题。由于网站结构差异很大，现有方法常常失败。此外，现有的微调和上下文学习技术无法在多个网站上推广。我们介绍 Wilbur，这是一种使用可微分排名模型和新颖的指令合成技术的方法，可以通过之前运行的任务演示来最佳地填充黑盒大型语言模型的提示。为了最大限度地提高端到端的成功率，我们还提出了一种智能回溯机制，可以学习错误并从错误中恢复。最后，我们展示了我们的排名模型可以根据生成自动课程的数据进行训练，该课程从法学硕士中采样代表性目标，运行代理并自动评估它，无需手动注释。 Wilbur 在 WebVoyager 基准测试中取得了最先进的结果，整体性能比纯文本模型高出 8%，在某些网站上高出 36%。在同一基准上，尽管仅接收文本输入，Wilbur 仍与强大的多模式模型相差不到 5%，进一步分析表明，大量故障是由于操作网络的工程挑战造成的。]]></description>
      <guid>https://arxiv.org/abs/2404.05902</guid>
      <pubDate>Fri, 12 Apr 2024 04:09:00 GMT</pubDate>
    </item>
    <item>
      <title>HGRN2：具有状态扩展的门控线性 RNN</title>
      <link>https://arxiv.org/abs/2404.07904</link>
      <description><![CDATA[分层门控线性 RNN（HGRN，Qin 等人，2023）在语言建模方面展示了有竞争力的训练速度和性能，同时提供了高效的推理。然而，HGRN 的循环状态大小仍然相对较小，这限制了其表达能力。为了解决这个问题，受线性注意力的启发，我们引入了一种简单的基于外积的状态扩展机制，以便在不影响循环状态大小的情况下显着扩大循环状态大小。引入任何附加参数。线性注意力形式还可以实现硬件高效的训练。我们的大量实验验证了 HGRN2 在语言建模、图像分类和 Long Range Arena 方面相对于 HGRN1 的优势。我们最大的 3B HGRN2 模型在语言建模方面略优于 Mamba 和 LLaMa Architecture Transformer。受控实验设置；并在下游评估中与许多开源 3B 模型竞争，同时使用更少的总训练令牌。]]></description>
      <guid>https://arxiv.org/abs/2404.07904</guid>
      <pubDate>Fri, 12 Apr 2024 04:03:43 GMT</pubDate>
    </item>
    <item>
      <title>语言模型合成数据的最佳实践和经验教训</title>
      <link>https://arxiv.org/abs/2404.07503</link>
      <description><![CDATA[人工智能模型的成功依赖于大型、多样化和高质量数据集的可用性，但由于数据稀缺、隐私问题和高成本，这些数据集的获取可能具有挑战性。通过生成模仿现实世界模式的人工数据，合成数据已成为一种有前途的解决方案。本文概述了合成数据研究，讨论了其应用、挑战和未来方向。我们提供现有技术的经验证据来证明其有效性，并强调确保其真实性、保真度和公正性的重要性。我们强调需要负责任地使用合成数据来构建更强大、更具包容性和值得信赖的语言模型。]]></description>
      <guid>https://arxiv.org/abs/2404.07503</guid>
      <pubDate>Fri, 12 Apr 2024 02:32:36 GMT</pubDate>
    </item>
    <item>
      <title>稀疏车道形成器</title>
      <link>https://arxiv.org/abs/2404.07821</link>
      <description><![CDATA[车道检测是自动驾驶的一项基本任务，随着深度学习的出现，车道检测取得了巨大的进步。以前基于锚点的方法通常设计密集的锚点，这些锚点高度依赖于训练数据集并在推理过程中保持固定。我们分析密集锚对于车道检测不是必需的，并提出了一种基于稀疏锚机制的基于变压器的车道检测框架。为此，我们使用位置感知车道查询和角度查询生成稀疏锚点，而不是传统的显式锚点。我们采用水平感知注意（HPA）来聚合沿水平方向的车道特征，并采用车道-角度交叉注意（LACA）来进行车道查询和角度查询之间的交互。我们还提出了基于可变形交叉注意的车道感知注意（LPA），以进一步细化车道预测。我们的方法名为 Sparse Laneformer，易于实现且可端到端训练。大量实验表明，Sparse Laneformer 的性能优于最先进的方法，例如，在具有相同 ResNet-34 主干的 CULane 上，在 MAC 更少的情况下，F1 分数超过 Laneformer 3.0%，F1 分数超过 O2SFormer 0.7%。]]></description>
      <guid>https://arxiv.org/abs/2404.07821</guid>
      <pubDate>Fri, 12 Apr 2024 02:24:03 GMT</pubDate>
    </item>
    <item>
      <title>在有限的时间间隔内应用指导可提高扩散模型中的样本和分布质量</title>
      <link>https://arxiv.org/abs/2404.07724</link>
      <description><![CDATA[引导是从图像生成扩散模型中提取最佳性能的关键技术。传统上，在图像的整个采样链中应用恒定的引导权重。我们表明，指导显然对链的开头（高噪音水平）有害，对末端（低噪音水平）基本上没有必要，并且只对中间有利。因此，我们将其限制在特定的噪声水平范围内，从而提高推理速度和结果质量。这种有限的指导区间显着提高了 ImageNet-512 中的记录 FID，从 1.81 提高到 1.40。我们证明，它在不同的采样器参数、网络架构和数据集（包括稳定扩散 XL 的大规模设置）中在数量和质量上都是有益的。因此，我们建议将指导间隔作为所有使用指导的扩散模型中的超参数。]]></description>
      <guid>https://arxiv.org/abs/2404.07724</guid>
      <pubDate>Fri, 12 Apr 2024 02:12:44 GMT</pubDate>
    </item>
    <item>
      <title>ControlNet++：通过高效的一致性反馈改进条件控制</title>
      <link>https://arxiv.org/abs/2404.07987</link>
      <description><![CDATA[为了增强文本到图像扩散模型的可控性，ControlNet 等现有工作结合了基于图像的条件控制。在本文中，我们揭示了现有方法在生成与图像条件控制一致的图像方面仍然面临重大挑战。为此，我们提出了 ControlNet++，这是一种新颖的方法，通过显式优化生成图像和条件控制之间的像素级循环一致性来改进可控生成。具体来说，对于输入条件控制，我们使用预训练的判别奖励模型来提取生成图像的相应条件，然后优化输入条件控制和提取条件之间的一致性损失。一种简单的实现是从随机噪声生成图像，然后计算一致性损失，但这种方法需要存储多个采样时间步长的梯度，从而导致相当多的时间和内存成本。为了解决这个问题，我们引入了一种有效的奖励策略，通过添加噪声故意干扰输入图像，然后使用单步去噪图像进行奖励微调。这避免了与图像采样相关的大量成本，从而可以更有效地进行奖励微调。大量实验表明ControlNet++显着提高了各种条件控制下的可控性。例如，在分割掩模、艺术线条边缘和深度条件方面，它比 ControlNet 分别提高了 7.9% mIoU、13.4% SSIM 和 7.6% RMSE。]]></description>
      <guid>https://arxiv.org/abs/2404.07987</guid>
      <pubDate>Fri, 12 Apr 2024 02:07:31 GMT</pubDate>
    </item>
    <item>
      <title>LLoCO：离线学习长上下文</title>
      <link>https://arxiv.org/abs/2404.07979</link>
      <description><![CDATA[由于自注意力机制的二次计算和内存开销以及生成过程中的大量 KV 缓存大小，处理长上下文仍然是大型语言模型 (LLM) 的一个挑战。我们提出了一种新方法来解决这个问题，通过上下文压缩和域内参数高效微调来离线学习上下文。我们的方法使法学硕士能够创建原始上下文的简明表示，并有效地检索相关信息以准确回答问题。我们引入了 LLoCO，这是一种使用 LoRA 结合上下文压缩、检索和参数高效微调的技术。我们的方法扩展了 4k 令牌 LLaMA2-7B 模型的有效上下文窗口，以处理多达 128k 令牌。我们在几个长上下文问答数据集上评估了我们的方法，证明 LLoCO 的性能显着优于上下文学习，同时在推理过程中使用的标记数量减少了 30 倍。 LLoCO 实现了高达 7.62 倍的加速，并大幅降低了长文档问答的成本，使其成为高效长上下文处理的有前景的解决方案。我们的代码可在 https://github.com/jeffreysijuntan/lloco 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07979</guid>
      <pubDate>Fri, 12 Apr 2024 02:05:04 GMT</pubDate>
    </item>
    <item>
      <title>OSWorld：真实计算机环境中开放式任务的多模式代理基准测试</title>
      <link>https://arxiv.org/abs/2404.07972</link>
      <description><![CDATA[以最少的人为干预完成复杂的计算机任务的自主代理有可能改变人机交互，显着提高可访问性和生产力。然而，现有的基准测试要么缺乏交互环境，要么仅限于特定应用程序或领域的环境，无法反映现实世界计算机使用的多样性和复杂性，从而限制了任务的范围和代理的可扩展性。为了解决这个问题，我们推出了 OSWorld，这是第一个可扩展的、用于多模式代理的真实计算机环境，支持任务设置、基于执行的评估以及跨各种操作系统（例如 Ubuntu、Windows 和 macOS）的交互式学习。 OSWorld 可以作为一个统一的、集成的计算机环境，用于评估涉及任意应用程序的开放式计算机任务。在 OSWorld 的基础上，我们创建了 369 项计算机任务的基准，涉及开放域中的真实 Web 和桌面应用程序、操作系统文件 I/O 以及跨多个应用程序的工作流程。每个任务示例均源自真实世界的计算机用例，包括详细的初始状态设置配置和基于自定义执行的评估脚本，以实现可靠、可重复的评估。对 OSWorld 上最先进的基于 LLM/VLM 的代理的广泛评估揭示了它们作为计算机助手的能力的重大缺陷。虽然人类可以完成 72.36% 以上的任务，但最好的模型仅取得 12.24% 的成功，主要是在 GUI 基础和操作知识方面遇到困难。使用 OSWorld 进行的综合分析为开发多模式通才代理提供了宝贵的见解，这是以前的基准测试无法实现的。我们的代码、环境、基线模型和数据可在 https://os-world.github.io 上公开获取。]]></description>
      <guid>https://arxiv.org/abs/2404.07972</guid>
      <pubDate>Fri, 12 Apr 2024 02:02:04 GMT</pubDate>
    </item>
    <item>
      <title>Ferret-v2：大型语言模型的参考和基础的改进基线</title>
      <link>https://arxiv.org/abs/2404.07973</link>
      <description><![CDATA[虽然 Ferret 将区域理解无缝集成到大语言模型 (LLM) 中，以促进其参考和基础能力，但它也存在一定的局限性：受到预先训练的固定视觉编码器的限制，无法在更广泛的任务上表现良好。在这项工作中，我们推出了 Ferret-v2，它是 Ferret 的重大升级，具有三个关键设计。 (1) 任何分辨率基础和参考：一种灵活的方法，可以轻松处理更高的图像分辨率，提高模型更详细地处理和理解图像的能力。 (2) 多粒度视觉编码：通过集成额外的 DINOv2 编码器，模型可以更好地学习和多样化的底层上下文，以获取全局和细粒度的视觉信息。 （3）三阶段训练范例：除了图像标题对齐之外，还提出了在最终指令调整之前进行高分辨率密集对齐的额外阶段。实验表明，由于其高分辨率缩放和细粒度视觉处理，Ferret-v2 比 Ferret 和其他最先进的方法有了显着的改进。]]></description>
      <guid>https://arxiv.org/abs/2404.07973</guid>
      <pubDate>Fri, 12 Apr 2024 01:44:20 GMT</pubDate>
    </item>
    <item>
      <title>Rho-1：并非所有代币都是您所需要的</title>
      <link>https://arxiv.org/abs/2404.07965</link>
      <description><![CDATA[以前的语言模型预训练方法对所有训练标记统一应用下一个标记预测损失。为了挑战这一规范，我们假设“并非语料库中的所有标记对于语言模型训练都同样重要”。我们的初步分析深入研究了语言模型的标记级训练动态，揭示了不同标记的不同损失模式。利用这些见解，我们引入了一种名为 Rho-1 的新语言模型。与学习预测语料库中每个下一个标记的传统 LM 不同，Rho-1 采用选择性语言模型 (SLM)，它有选择地训练与所需分布一致的有用标记。这种方法涉及使用参考模型对预训练标记进行评分，然后将损失集中在具有较高超额损失的标记上来训练语言模型。当在 15B OpenWebMath 语料库上进行持续预训练时，Rho-1 在 9 项数学任务中的小样本准确率绝对提高了 30%。经过微调后，Rho-1-1B 和 7B 在 MATH 数据集上分别取得了 40.6% 和 51.8% 的最先进结果 - 仅用 3% 的预训练标记与 DeepSeekMath 相匹配。此外，在对 80B 个通用标记进行预训练时，Rho-1 在 15 个不同任务中实现了 6.8% 的平均增强，提高了语言模型预训练的效率和性能。]]></description>
      <guid>https://arxiv.org/abs/2404.07965</guid>
      <pubDate>Fri, 12 Apr 2024 01:41:31 GMT</pubDate>
    </item>
    </channel>
</rss>