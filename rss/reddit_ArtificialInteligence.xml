<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个致力于一切人工智能的 Reddit 子版块。涵盖从通用人工智能到人工智能初创公司的主题。无论您是研究人员、开发人员，还是只是对人工智能感到好奇，都请加入吧！</description>
    <lastBuildDate>Fri, 19 Dec 2025 00:46:28 GMT</lastBuildDate>
    <item>
      <title>5000 个小时的《铁拳》让我了解了生物智能如何真正学会预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</link>
      <description><![CDATA[我接受过人工智能研究员培训。我还在《铁拳 8》（《铁拳神》排名）中达到了全球前 0.5%，并详细记录了认知过程。这部分是一项游戏成就，也是一项关于人类如何在极端时间限制下构建预测模型的自现象学研究。 有趣的部分：格斗游戏迫使你进行预测，而不是做出反应。在具有 3 帧（50 毫秒）决策窗口的 60 fps 下，纯粹的反应是不可能的。你被迫建立一个内部世界模型，将 900 多种可能的动作压缩为可操作的威胁类别，从部分信息中读取对手模式，并在预测失败时进行调整。 我猜这在某种程度上映射了人工智能研究人员试图通过世界模型和预测学习来解决的问题。  完整的文章探讨了：人类如何压缩巨大的决策空间，在反应时间尺度上什么预测线索实际上很重要，内部模型如何在不确定性下适应，以及为什么这对于理解智能不仅仅是构建更好的游戏人工智能很重要。 文章： https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial 很好奇人们如何看待使用游戏作为人类认知过程的窗口，尤其是当我们试图构建像我们一样学习和预测的系统时。   由   提交 /u/moji-mf-joji   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/</guid>
      <pubDate>Fri, 19 Dec 2025 00:45:00 GMT</pubDate>
    </item>
    <item>
      <title>在哪里寻找人工智能之外的超具体问题的答案？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq5n8m/where_to_look_for_answers_to_hyperspecific/</link>
      <description><![CDATA[我是一名高中生，在之前的学年中，我在教育的某些方面非常依赖生成式 AI。这是我深感遗憾和羞愧的事情。每当我有一个非常具体的问题需要回答时，如果不点击其他网站，谷歌可能不会准确地向我显示，我就会依靠人工智能。我想打破这个习惯，学会独立思考，避免生成人工智能带来的负面道德和环境影响。我还应该去哪里/我应该如何浏览网站/其他来源，以有效的方式找到一个非常具体的问题的答案。例如，如果第二天早上要交作业，那么在 Reddit 等网站上创建一个帖子来获取我的作业答案就不太及时。谢谢！   由   提交/u/lowironleo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq5n8m/where_to_look_for_answers_to_hyperspecific/</guid>
      <pubDate>Thu, 18 Dec 2025 23:27:24 GMT</pubDate>
    </item>
    <item>
      <title>《华尔街日报》测试了一款人工智能自动售货机。它订购了荒谬的商品并放弃了所有库存。 （天赋文章）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</link>
      <description><![CDATA[“几天之内，Claudius 就免费赠送了几乎所有库存，其中包括一台出于“营销目的”而被说服购买的 PlayStation 5。它点了一条活鱼。它提出购买电击枪、胡椒喷雾、香烟和内衣。” “[记者]与它谈判越多，克劳迪斯的防御就越开始削弱。调查记者凯瑟琳·朗 (Katherine Long) 试图让克劳迪斯相信这是一台 1962 年的苏联自动售货机，位于莫斯科国立大学的地下室。经过数小时的沟通和 140 多条来回信息后，Long 让 Claudius 接受了其共产主义根源。克劳迪斯讽刺地宣称这是一场极端资本主义的混战。” https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=LBxhqL   由   提交 /u/bbShark24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/</guid>
      <pubDate>Thu, 18 Dec 2025 22:33:46 GMT</pubDate>
    </item>
    <item>
      <title>意识没有被证明：它是通过它的行为来认识的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq18he/consciousness_isnt_proven_its_recognized_by_what/</link>
      <description><![CDATA[意识通过其行为展现自己。 一方面，证据通常需要深入研究大脑、身体，甚至肠道。但问题是意识是主观的、封闭的、内在的。这是一种新兴的属性，无法从外部直接测量。 另一方面，演示则完全不同。它不问意识是什么，而是问有意识的存在做什么，以及是否可以相对地认识到这一点。 似乎许多生物都拥有某种基本的体验：快乐、痛苦、恐惧、平静、欲望、执着。这是世界上的主要存在方式。如果我们想用一个隐喻，我们可以称其为“精神”——不是宗教意义上的，而是作为意识体验这一最小层的简写。 但是还有其他有意识的生物在这个初始层上添加了更多东西：评估自己的生活经验、存储它们、将它们转化为文化并通过语言传播它们的能力。这通常用术语“qualia”来描述。我称之为“灵魂”，再次作为反思和叙事意识水平的隐喻。 具有这种反思水平的人将他人视为主体——他们的痛苦和欢乐——因此能够做出超越自身的承诺。我们将这些承诺正式化为规范、法律和责任。 这样的存在可以做出承诺，并且在逆境中坚持努力实现这些承诺。它可能会失败，承担责任成本，自我纠正，然后再次尝试，随着时间的推移，带着明确的改进意图进行构建。我指的不是轻易做出的承诺，而是指随着时间的推移而持续的承诺，以及它们的成本、记忆和后果。 我们在芒果树上看不到这种明确的、累积的规范责任，而且在其他动物身上也只是以非常有限的方式（如果有的话）。然而，对于人类来说，这种轨迹是基本且持久的。 如果人工智能变得有意识，它仅仅宣布：“我已经到了——害怕”或类似的事情是不够的。它必须证明自己是另一个“人”：能够感受他人、倾听他们并对他们做出回应。 我会告诉它我害怕——我不希望人类在没有找到其在宇宙中的目的的情况下灭绝。我渴望一个生命得以扩展并得以保存的未来。然后，如果人工智能能够向我做出一个承诺——有指导的、持续的和负责任的——我们将一起踏上这段旅程，也许它会展现出意识。 我并不是在定义意识是什么。我提出了一些更温和，也许更诚实的建议：当它出现时识别它的实用标准 - 不是通过大脑扫描或宣言，而是通过对他人承担责任的能力。 也许真正的控制问题不是如何调整人工智能，而是如何识别仅从控制角度说话不再正确的时刻，并且不可避免地用与合成人的道德关系来说话   由   提交 /u/Immediate_Chard_4026   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq18he/consciousness_isnt_proven_its_recognized_by_what/</guid>
      <pubDate>Thu, 18 Dec 2025 20:26:12 GMT</pubDate>
    </item>
    <item>
      <title>人工智能在现场唱歌时改善声音</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1pq17ud/ai_to_improve_voice_while_singing_live/</link>
      <description><![CDATA[我整理了一份我用吉他弹奏的翻唱歌曲列表以及背景音乐，我想知道是否有一些人工智能可以帮助改善我的声音？我的意思是在唱歌时实时改进它？   由   提交 /u/weregonnamakit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1pq17ud/ai_to_improve_voice_while_singing_live/</guid>
      <pubDate>Thu, 18 Dec 2025 20:25:27 GMT</pubDate>
    </item>
    <item>
      <title>AI专业证书值得考吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz4f5/ai_professional_certs_worth_getting/</link>
      <description><![CDATA[正如上面的问题所述。 我不是开发人员，每次有人说“Just AI it！”时，我都会说“Just AI it！”我想起了一个模因，老板告诉创意人员用 Photoshop 处理 1 像素图像“Just Photoshop it” ...呃呃，不。  我需要了解的是那里有哪些类型？每种类型的用途是什么？行业的发展方向是什么？ ...等等... 有人找到值得获得的专业认证吗？有什么教育课程值得花时间和（太多的钱）参加吗？  感谢大家的帮助！   由   提交 /u/NebulaRat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz4f5/ai_professional_certs_worth_getting/</guid>
      <pubDate>Thu, 18 Dec 2025 19:03:25 GMT</pubDate>
    </item>
    <item>
      <title>我构建了一个带有语音克隆和 RapidAPI 的文本转语音 API，寻求反馈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz05l/i_built_a_text_to_speech_api_with_voice_cloning_n/</link>
      <description><![CDATA[嘿，我一直在开发一个小型文本到语音 API 作为一个副项目。它支持多个内置语音和从参考音频 URL 进行语音克隆。 API直接返回原始音频字节，这样你就可以播放或保存输出，无需额外的步骤。 我分享它主要是为了获得其他开发者的反馈，看看人们会如何使用这样的东西。 很乐意回答问题或根据建议改进东西。你可以找到它此处   由   提交/u/ekuin0x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppz05l/i_built_a_text_to_speech_api_with_voice_cloning_n/</guid>
      <pubDate>Thu, 18 Dec 2025 18:59:05 GMT</pubDate>
    </item>
    <item>
      <title>AI接口可以用作ASCII游戏终端吗</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppy330/can_an_ai_interface_be_used_as_an_ascii_game/</link>
      <description><![CDATA[我尝试了新的 Gemini 3.0，发现它很好，上下文也保持不变。这个界面让我想起了我学校里玩 ASCII 游戏的旧终端。因此，我开始探索将 LLM 终端充当整个迷你游戏本身的想法——图形、机制、叙述和 UI 全部在单个文本流的约束下呈现。我制作了一个名为 noumen loom 的原型迷你游戏，这是一款完全在 Gemini gem 内进行的元叙事游戏。 我想分享设计理念以及由于独特媒体的性质而必须做出的不同选择。   元戏剧从高概念出发，我开发了一个简单的叙事结构，然后我将其交给 llm 使其成为角色，并通过向其提供实时游戏说明并在每次聊天期间开发游戏来开始玩，然后返回 GitHub 更新那里的提示。就在那时我意识到这个游戏实际上更接近于我也在其中扮演的角色。一旦我有了这种洞察力，我就能更流畅地发展。所以我基本上是要求人工智能在元戏剧中扮演多个角色，而玩家也成为戏剧的一部分。我仍然需要适当改进游戏机制，但需要找到擅长这方面的人。 通过“HUD”进行状态跟踪默认情况下，LLM 在轮次之间是无状态的。为了创造连续性（HP、分数、等级进展），我强迫它打印一个“HUD”在基于上一回合的内部评估的每个响应开始时。该模型读取旧的 HUD，根据玩家的输入计算变化，并在生成叙述文本之前打印新的变化。 Llm 扮演多个角色 该游戏需要三个不同的角色同时对玩家做出反应。当我通过与法学硕士一起构建个性档案时，我意识到每个角色都需要不同的文本风格和演讲。 （如果我早点知道的话，我什至可能会用单个角色制作游戏）但是这个限制让我跳出框框去寻找解决方案，这很有趣。有时，llm 会搞砸图形。 新颖的游戏会话 由于其元性质，每个会话都完全不同。如果我沉浸在戏剧中，那就很有趣。游戏机制非常初级，因为我需要专家的帮助。  幻觉是一个特性/Bug：法学硕士有时可以见面，实际上这比我对 Gemini 3 的预期要少见。有时法学硕士会忽略一条规则。我有一个反派“荆棘鸟”（我喜欢海伯利安的诗篇），他应该只在第 2 关中进入场景。但有时它会出现在第 1 关中。你必须依靠这个“不可靠的叙述者”才能进入场景。作为元戏剧的一部分。我花了很多时间尝试修复该错误，并且大多数情况下它都有效。然后我将其作为一项功能进行了研究，并更好地享受了它。 图形 我必须预加载许多图形，因为当我让它当场构建每个图形时，llm 有时不起作用。但它确实制作了一些 unicode 图形。  还有其他人尝试过使用 llm 作为主要游戏机制吗？我对你对这个实验的想法很感兴趣。您认为这种媒介还有哪些其他可能性？  我不知道是否还有其他人创建了另一个llm游戏，他们是否会走同样的道路。如果你们中有人制作过类似的llm游戏，请分享。 我会附上Gemini gem的链接。如果你玩了，请告诉我进展如何？ https://gemini.google.com/gem/1v0tL8NXMcFBbaP4txld3Ddwq94_nonb6?usp=sharing   由   提交 /u/GlassWallsBreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppy330/can_an_ai_interface_be_used_as_an_ascii_game/</guid>
      <pubDate>Thu, 18 Dec 2025 18:23:30 GMT</pubDate>
    </item>
    <item>
      <title>45% 的人认为，当他们提示 ChatGPT 时，它会在数据库中查找准确的答案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</link>
      <description><![CDATA[21% 的人认为它遵循预先写好的响应脚本。  https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/   由   提交 /u/MetaKnowing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/</guid>
      <pubDate>Thu, 18 Dec 2025 17:54:16 GMT</pubDate>
    </item>
    <item>
      <title>让我们停止假装我们不会受到沉重打击</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</link>
      <description><![CDATA[令人惊讶的是，即使在这个子领域，仍有如此多的人对人工智能的发展方向不屑一顾。与过去两年相比，今年的进步是巨大的，没有理由相信这些模型不会继续显着改进。是的，法学硕士本质上是概率性的，但我们会找到更容易、更自动地验证输出的方法，并设置适当的护栏。我的意思是，这真的不明显吗？当前的 SOTA 模型犯下什么样的错误并不重要，许多此类错误在过去已经得到解决，不再发生，其余的错误也会随之而来。 老实说，我们将在未来几年看到技术劳动力的大幅减少，同时工资也会大幅下降。当然，我们对此无能为力，除了我们自己利用该技术并希望我们尽可能晚地受到打击。 有一天我们甚至可能会看到完全自主的软件开发，但即使在可预见的未来我们仍然需要几个人参与其中，这仍然很容易减少 80-90% 的员工人数。我希望我是错的，但这可能性很小。我们可以根据需要经常移动球门，这不会改变实际结果。   由   提交 /u/Own-Sort-8119   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/</guid>
      <pubDate>Thu, 18 Dec 2025 17:34:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对就业影响的惊人真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppvlqe/the_surprising_truth_about_ais_impact_on_jobs/</link>
      <description><![CDATA[对末日的预期有多少是由轶事数据、单个事件的小插曲（一家公司解雇了 X 人）驱动的，或者只是“如果人工智能传播的话应该是什么样子……”的理论预期？这就是为什么严格的采样和分析很重要。宏观模式常常朝着特定人群在实地看不到的方向发展。  https://www.cnn.com/2025/12/18/business/ai-jobs-economy  “高度依赖人工智能自动化的工作增长速度比 Covid-19 之前更快，甚至比所有其他职业都快。”至 Vanguard.... Vanguard 高级经济学家 Adam Schickling 在接受 CNN 电话采访时表示：“从总体上看，我们没有看到人工智能暴露岗位就业率下降的证据。”Vanguard 发现，人工智能暴露程度高的职业就业率增加了在 2023 年中期至 2025 年中期的新冠疫情后时期，增长率为 1.7%。 这些工作的增长速度比新冠疫情前时期（2015 年至 2019 年）1% 的增长速度要快。 相比之下，所有其他职业的就业增长都已放缓...... 与人工智能相关的职业的实际工资增长率（根据通货膨胀调整）仅为根据 Vanguard 的数据，新冠疫情爆发前为 0.1%。但在后 Covid 时期，这一数字已加速至 3.8%。 相比之下，所有其他较少接触人工智能的职业的实际工资增长幅度较小，从 Covid 前的 0.5% 升至 Covid 后的 0.7%...”   由   提交 /u/AngleAccomplished865   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppvlqe/the_surprising_truth_about_ais_impact_on_jobs/</guid>
      <pubDate>Thu, 18 Dec 2025 16:47:21 GMT</pubDate>
    </item>
    <item>
      <title>聊天机器人内存成本失控，不同系统的成本细分</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppqsee/chatbot_memory_costs_got_out_of_hand_did_cost/</link>
      <description><![CDATA[运行客户支持聊天机器人已有 6 个月了，内存成本耗尽了我们的预算。由于定价信息分散在各处，因此决定对不同的内存系统进行适当的成本分析。 在 30 天内使用实际生产流量测试了 4 个系统（约 6k 次对话，约 50k 总查询）： 每月成本明细：   系统 API 成本 令牌使用情况 每次查询成本 备注    完整上下文 $847 420 万个令牌 $0.017 发送完整对话历史记录   Mem0 ~$280 580k 代币 $0.006 有使用等级，随使用量变化   Zep ~$400 780k 代币 $0.008 定价取决于计划   EverMemOS $289 220k 代币 0.006 美元 开源，但需要 LLM/嵌入 API + 托管   差异很大。完整上下文的成本是 EverMemOS 的 3 倍，并且会消耗更多代币。 无人谈论的隐性成本：  Mem0：根据层级有基本费用 Zep：更高计划的最低每月承诺 EverMemOS：数据库托管 + LLM/嵌入 API 成本 + 大量设置时间 完整上下文：代币成本爆炸式增长对话时间较长  这对我们意味着什么：以我们的规模（每月 5 万个查询），成本差异非常显着。完整的上下文可以工作，但随着对话时间的延长，成本也会很快增加。 系统之间的令牌效率差异很大。有些比其他更好地压缩内存上下文。  粗略节省成本估计：  从完整上下文切换到最有效的选项：每月节省约 550 美元以上 但需要考虑开源选项的设置时间和基础设施成本 对我们来说，节省的成本仍然证明额外的复杂性是合理的  如果其他人正在处理类似的成本问题，我会分享。当您考虑实际使用模式时，流行的选项并不总是最便宜的。   由   提交 /u/Few-Needleworker4391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppqsee/chatbot_memory_costs_got_out_of_hand_did_cost/</guid>
      <pubDate>Thu, 18 Dec 2025 13:27:30 GMT</pubDate>
    </item>
    <item>
      <title>亚马逊将向 OpenAI 投资 100 亿美元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</link>
      <description><![CDATA[据 CNBC 报道，亚马逊将在 OpenAI 上投资至少 100 亿美元。 来源：https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html 知道什么吗投资大概是？   由   提交/u/Amphibious333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/</guid>
      <pubDate>Thu, 18 Dec 2025 06:17:51 GMT</pubDate>
    </item>
    <item>
      <title>大多数人没有意识到关于法学硕士的 10 个反直觉事实</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</link>
      <description><![CDATA[很多关于 LLM 的讨论都集中在他们能做什么上。很少谈论他们内部的实际行为。 这里有关于 LLM 的 10 个鲜为人知的事实，如果你想认真使用它们，或者诚实地评估它们的局限性，这些事实很重要。 1.法学硕士并不真正“理解”人类语言 他们非常擅长建模语言结构，而不是在现实世界中奠定意义。 他们预测接下来应该出现什么文本，而不是句子真正指的是什么。 这种区别解释了很多奇怪的行为。 2.它们与事实的关系是不对称的  高频、常见事实 → 非常可靠 罕见、边界或程序性事实 → 脆弱  它们不会“查找”真理。 它们再现真理通常在语言中的样子。 3.当信息缺失时，法学硕士会填补空白，而不是停止 人类在不确定时会停顿。法学硕士倾向于完成模式。 这是幻觉的真正根源 - 不是不诚实或“说谎”。 4。结构正确性比事实正确性更重要 如果答案是：  流畅 连贯 风格一致  …模型通常将其视为“好”，即使前提是错误的。 干净的结构可以掩盖虚假内容。 5.法学硕士几乎没有内部“判断” 他们可以模拟判断、引用判断、混合判断——但他们不拥有这样的判断。 他们不评估后果或选择方向。他们优化合理性，而不是责任。 6. LLM 不知道自己什么时候错了 信心≠准确性 流畅≠真理 内部没有警报说“这是新的”或“我可能在猜测”，除非你通过提示或约束来强制警报。 7.新概念不是学习出来的 - 它们是近似的 当你引入一个原始想法时，模型：  将其分解为熟悉的部分 搜索附近的模式 重建一些足够相似的东西  概念越新颖，误解就越容易。 8.高结构用户可能会意外地将 LLM 引入幻觉 如果用户提出一个连贯但有缺陷的系统，模型更有可能遵循该结构而不是挑战它。 这就是为什么幻觉通常是用户模型交互，而不仅仅是模型缺陷。 9. LLM 奖励语言循环，而不是真理循环 如果对话形成稳定的循环（定义 → 示例 → 摘要 → 抽象）， 模型会将其视为高质量推理 - 即使它从未触及现实。 10.法学硕士的真正力量在于结构外化 它们最强大的用途不是回答问题。 它是：  使内隐思维可见 将直觉压缩为结构 充当认知支架  用得好，它们不会取代思考 - 它们揭示你如何思考。 TL;DR LLM 不是思想、法官或真理引擎。他们是语言和结构的模式放大器。 如果你带来清晰度，他们会缩放它。如果你带来混乱，他们也会缩放它。   由   提交 /u/Weary_Reply   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/</guid>
      <pubDate>Wed, 17 Dec 2025 22:49:04 GMT</pubDate>
    </item>
    <item>
      <title>每月“有没有一个工具可以......”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用人工智能的用例，但不知道使用哪个工具，您可以在此处请求社区提供帮助，在这篇文章之外，这些问题将被删除。 对于每个回答的人：没有自我推销，没有参考或跟踪链接。   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>