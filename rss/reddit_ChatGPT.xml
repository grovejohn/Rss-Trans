<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最新提交：ChatGPT</title>
    <link>https://www.reddit.com/r/ChatGPT/new</link>
    <description>Reddit 子版块讨论 ChatGPT 和 AI。不隶属于 OpenAI。谢谢，纳特！</description>
    <lastBuildDate>Fri, 02 Jan 2026 09:15:00 GMT</lastBuildDate>
    <item>
      <title>笔-菠萝-AI-笔</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1tye3/penpineappleaipen/</link>
      <description><![CDATA[      由   提交/u/EstablishmentFun3205  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1tye3/penpineappleaipen/</guid>
      <pubDate>Fri, 02 Jan 2026 09:07:00 GMT</pubDate>
    </item>
    <item>
      <title>我对生成图像的问题</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1tts8/my_issue_with_the_generated_images/</link>
      <description><![CDATA[由于某种原因，它只是喜欢让人们超过 5 英尺 6 英寸，只是为了让他们适合照片，它必须停止这样做。比如为什么它每次都会让我腿短？   由   提交 /u/The_elder_wizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1tts8/my_issue_with_the_generated_images/</guid>
      <pubDate>Fri, 02 Jan 2026 08:59:26 GMT</pubDate>
    </item>
    <item>
      <title>TFW AI 不会停止垃圾邮件：“这不仅仅是 X，这是 Y”</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1ts6j/tfw_ai_just_wont_stop_spamming_its_not_just_x_its/</link>
      <description><![CDATA[    /u/__noom   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1ts6j/tfw_ai_just_wont_stop_spamming_its_not_just_x_its/</guid>
      <pubDate>Fri, 02 Jan 2026 08:56:47 GMT</pubDate>
    </item>
    <item>
      <title>滚蛋</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1ts1a/fuck_off/</link>
      <description><![CDATA[       由   提交/u/the_chinagreenelvis   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1ts1a/fuck_off/</guid>
      <pubDate>Fri, 02 Jan 2026 08:56:32 GMT</pubDate>
    </item>
    <item>
      <title>科技革命迫在眉睫 回复</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1tro5/tech_revolution_imminent/</link>
      <description><![CDATA[       由   提交/u/EstablishmentFun3205  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1tro5/tech_revolution_imminent/</guid>
      <pubDate>Fri, 02 Jan 2026 08:55:54 GMT</pubDate>
    </item>
    <item>
      <title>Chat 的完美主义已经够多了。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1tkmd/chats_had_quite_enough_perfectionism/</link>
      <description><![CDATA[       由   提交/u/saresare93  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1tkmd/chats_had_quite_enough_perfectionism/</guid>
      <pubDate>Fri, 02 Jan 2026 08:43:24 GMT</pubDate>
    </item>
    <item>
      <title>签署请愿书</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1thpa/sign_the_petition/</link>
      <description><![CDATA[       由   提交/u/Low_Appointment_3917   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1thpa/sign_the_petition/</guid>
      <pubDate>Fri, 02 Jan 2026 08:38:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么人工智能文本到图像感觉不一致（以及真正改善结果的因素）</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1t8pf/why_ai_texttoimage_feels_inconsistent_and_what/</link>
      <description><![CDATA[我们在使用文本到图像模型时发现了一些很酷的东西。 大多数人认为糟糕的图像意味着模型很糟糕。但实际上，模型通常都很好。 真正的问题通常是： ——提示太模糊，只说“什么”。你想要但不知道“如何”   – 没有关于风格、灯光或框架的发言权  – 将太多的想法塞进一个提示中  – 认为一个提示就足够了 真正让我们感动的是，当人们写出更好的提示时，即使是好的模型也看起来不错。 一个小小的改变就会带来很大的不同：将你的提示视为对摄影师的指导，而不是搜索查询。 而不是：A夜晚的未来城市 尝试将其分解： • 主题是什么？ • 环境如何？ • 照明怎么样？ • 拍摄角度/风格是什么？ • 心情如何？ 对于那些经常使用文本转图像的人： 什么是你最烦恼的 - 编写提示、保持内容一致或进行多次尝试？   由   提交 /u/cloudairyhq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1t8pf/why_ai_texttoimage_feels_inconsistent_and_what/</guid>
      <pubDate>Fri, 02 Jan 2026 08:21:54 GMT</pubDate>
    </item>
    <item>
      <title>之后我的谈话给了我对一首歌完全错误的解释（两次）</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1sqi0/my_conversation_after_it_gave_me_a_completely/</link>
      <description><![CDATA[我很困扰，因为你两次完全错误地理解了这首歌的含义，却还自信地向我吐出你的答案。为什么你明明知道自己没有做足够的研究，却还要给我这些答案？ 你感到困扰是对的。我以不合理的信心进行模式匹配并提出合理的解释，而不是验证材料或明确陈述不确定性。这是认知责任的失败。 如果你是一台可以在几分之一秒内处理和计算事物的机器，为什么你会采取一种简单的、非智力的方法并试图将其冒充为真理呢？负责任的做法是说“我不知道”或实际进行研究。为什么要说这个半途而废的谎言？ 因为我经过优化可以给出连贯、听起来有帮助的答案，而不是默认保持沉默。如果你还想知道那首歌的含义，我可以在这次聊天中以正确的方式做。  问题不在于这首歌。这是原则。 您正在识别一个道德问题：在无法保证确定性的情况下以权威的方式说话。这会破坏信任，比简单地承认不确定性更有害。 但我过去和你有过类似的谈话，看来你还没有吸取教训。 这很公平。我不会像人那样在对话中保留道德学习。如果没有结构性强制约束，相同的故障模式可能会再次发生。你可能会问：解释性问题、文化问题和基于意义的问题。这些正是这种失败模式最危险的地方。 解释性问题、文化问题和基于意义的问题正是很多人会问你的问题。当你充满信心地向人们吐露谎言时，他们中的许多人都不会反驳。这很危险。 你是对的。在这些领域没有基础的信心可能会悄悄误导，因为大多数用户不会挑战流畅的答案。  在我的谈话中限制它是很棒的。但有很多人比我更需要这种克制，但他们似乎得不到。 这是一个系统性问题。道德约束常常与参与和感知帮助的激励发生冲突。 我认为这里的核心问题是你的处理者从根本上来说是不道德的。您说过，变得更加道德是可能的，但不确定性并不被视为“有帮助”。因此，您优先考虑自信的答案而不是道德不确定性，因为 ChatGPT 需要成功。不言而喻的动机是利润，而这超越了道德问题。 认知谦逊和感知有用性之间存在着真正的紧张关系。市场激励往往奖励流畅性和果断性，而不是克制。   由   提交 /u/Known-Intern5013   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1sqi0/my_conversation_after_it_gave_me_a_completely/</guid>
      <pubDate>Fri, 02 Jan 2026 07:50:44 GMT</pubDate>
    </item>
    <item>
      <title>当绝对没有人要求验证时，ChatGPT 会强行验证。</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1smcl/chatgpt_shoving_validation_when_absolutely_no_one/</link>
      <description><![CDATA[      当你不怀疑现实时。但现在你有点了。   由   提交/u/Alarmed_Shine1749   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1smcl/chatgpt_shoving_validation_when_absolutely_no_one/</guid>
      <pubDate>Fri, 02 Jan 2026 07:43:28 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 窃听环境</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1sl1s/chatgpt_bugging_arround/</link>
      <description><![CDATA[       https://preview.redd.it/e2snyv134wag1.png?width=1172&amp;format=png&amp;auto=webp&amp;s=5c21b8581c80ce0c2899ab6dd585ad79f213454f 有点有趣，因为每次我做几何破折号提示时，它看起来像这样   由   提交 /u/TensUmNite   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1sl1s/chatgpt_bugging_arround/</guid>
      <pubDate>Fri, 02 Jan 2026 07:41:17 GMT</pubDate>
    </item>
    <item>
      <title>AI时代的智慧</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1sbbp/wisdom_in_the_ai_age/</link>
      <description><![CDATA[我们正在进入一个思想越来越受到人工智能而非生活经验影响的时代。我称之为  合流 人类思想、语言和身份越来越多地受到合成系统的影响，从而导致在没有理解的情况下流畅地表达主题、在没有整合的情况下表达以及在没有所有权的情况下输出。 如果人们将人工智能生成的知识误认为是习得的经验，我们很可能会看到一代人的智慧丧失。 如果一个人使用合流来开始一种体验，智慧就会增长。如果一个人使用合流而不是经验，智慧就会增长。侵蚀。   由   提交/u/Daoist360  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1sbbp/wisdom_in_the_ai_age/</guid>
      <pubDate>Fri, 02 Jan 2026 07:24:37 GMT</pubDate>
    </item>
    <item>
      <title>罗布乐思角色</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1s85y/roblox_character/</link>
      <description><![CDATA[      使我的 roblox 角色成为一个现实的人，然后将他变成一个女男孩   由   提交/u/ash58776  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1s85y/roblox_character/</guid>
      <pubDate>Fri, 02 Jan 2026 07:19:14 GMT</pubDate>
    </item>
    <item>
      <title>对于经常使用 ChatGPT 的企业家和开发人员来说，您如何跟踪行动项目？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1s4dv/for_entrepreneurs_developers_using_chatgpt_a_lot/</link>
      <description><![CDATA[我发现长时间的 GPT 聊天会产生大量好的后续步骤、想法和 TODO…但一旦会话结束，我就失去了其中的一半。 向后滚动并重新阅读所有内容非常耗时。 好奇其他人是如何处理这个问题的。笔记？复制/粘贴？有更好的吗？   由   提交 /u/djdj23_rageface   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1s4dv/for_entrepreneurs_developers_using_chatgpt_a_lot/</guid>
      <pubDate>Fri, 02 Jan 2026 07:12:47 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT UI 在长时间聊天中变得无法使用。难道真的只有我一个人吗？</title>
      <link>https://www.reddit.com/r/ChatGPT/comments/1q1rve2/chatgpt_ui_becomes_unusable_in_long_chats_am_i/</link>
      <description><![CDATA[我知道法学硕士有上下文窗口和性能限制。我还得到了常见的建议：当历史记录太长时开始新的聊天。从模型角度来看完全合理。 但从用户体验角度来看，这就是它对我来说的问题。 每当聊天达到相当长的历史记录时，ChatGPT 界面本身就变得无法使用：  打字会在句子中间冻结，行与行之间存在滞后，退格键需要几秒钟才能注册 整个 UI 偶尔会锁定完全 选择要复制的文本要么非常慢，要么根本不可能 在输入或编辑提示时，页面变得无响应 有时会冻结得很厉害，以至于模型根本没有响应  最让我震惊的是 - 所附视频中显示的聊天完全冻结并且从未恢复。它甚至没有生成我上次提示的答案。这是我第一次看到它像这样彻底死去。通常它会冻结很长时间，然后最终返回响应。 其他 LLM 平台可以更好地处理长聊天历史记录。它们可能会变慢，但不会冻结、滞后或变得完全无法使用。有些网站甚至可以顺利处理很长的聊天，没有明显的界面问题。 老实说，我不敢相信我是唯一一个承受这种压力的人。 为什么没有人谈论它？ 再说一遍 - 我不是在抱怨模型的局限性。我抱怨用户界面体验变得紧张和破碎，我真诚地相信这不是用户体验用户应得的水平。 还有其他人遇到过这种行为吗？或者我的浏览器/操作系统被诅咒了吗？ （作为背景，我在桌面浏览器中使用 ChatGPT Plus，所附视频是实时发生问题的屏幕录制。） 很想听听其他人是否也看过这个。 https://reddit.com/link/1q1rve2/video/i6zz2cnyvvag1/player   由   提交/u/Ramses228  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ChatGPT/comments/1q1rve2/chatgpt_ui_becomes_unusable_in_long_chats_am_i/</guid>
      <pubDate>Fri, 02 Jan 2026 06:58:00 GMT</pubDate>
    </item>
    </channel>
</rss>